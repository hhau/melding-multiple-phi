---
title: "Submodels, priors, and pooling the link parameters in the survival example"
author: "Andrew Manderson"
date: "`r format(Sys.time(), '%d %B, %Y')`"
fontfamily: tgpagella
fontsize: 10pt
papersize: a4
geometry: margin=2.25cm
bibliography: ../bibliography/multi-phi-bib.bib
csl: ../bibliography/journal-of-the-royal-statistical-society.csl
link-citations: true
hyperrefoptions:
  - backref
  - colorlinks=true
output:
  pdf_document:
    includes:
      in_header:
        ../tex-input/pre.tex
    fig_caption: true
    number_sections: true
    keep_tex: true
---

<!--
Rscript -e 'rmarkdown::render("rmd-reports/2021-05-06_survival-pooling.rmd")'
-->

```{r setup, include = FALSE, cache = FALSE, message = FALSE, warning = FALSE, comment = NA}
options(width = 9999)
knitr::opts_chunk$set(
  echo = FALSE, cache = FALSE, fig.align = 'center')
```

# Models

There are $i = 1, \ldots, N$ individuals (icustays) in the data set.
Each individual is admitted to the ICU at time $0$, and is discharged or expires at time $C_{i}$.

## P/F ratio model (B-spline): $\pd_{1}$

Each individual has $j = 1, \ldots, J_{i}$ P/F ratio observations $z_{i, j}$ at times $t_{i, j}$ where $\boldsymbol{z}_{i} = (z_{i, 1}, \ldots, z_{i, J_{i}})$ and $\boldsymbol{t}_{i} = (t_{i, 1}, \ldots, t_{i, J_{i}})$.
We choose to model the P/F ratio using a B-spline of degree 3, with 2 boundary knots and 7 internal knots, and do not include an intercept column in the spline basis.
The lower boundary knot is placed at $\min(\boldsymbol{t_{i}})$ and the upper boundary knot is placed at $\max(\boldsymbol{t_{i}})$.
The internal knots are evenly spaced between the two boundary knots.
These choices result in $k = 1, \ldots, 10$ spline basis terms per individual, with coefficients $\zeta_{i, k}$ where $\boldsymbol{\zeta}_{i} = (\zeta_{i, 1}, \ldots, \zeta_{i, 10})$.
We denote the individual specific B-spline basis evaluated at time $t_{i, j}$ as $B_{i}(t_{i, j}) \in \left\{\mathbb{R}_{+} \cup \{0\}\right\}^{10}$.

An individual's P/F data are standardised to improve computational performance.
That is to say we actually observe $\tilde{z}_{i, j}$, which are then rescaled by each individual's mean $\overline{z}_{i}$ and standard deviation $\hat{s}_{i}$ such that $z_{i, j} = \frac{\tilde{z}_{i, j} - \overline{z}_{i}}{\hat{s}_{i}}$.
The ARDS threshold is rescaled for each individual, i.e. $\tau_{i} = \frac{300 - \overline{z}_{i}}{\hat{s}_{i}}$.

We write the submodel
\begin{equation}
\begin{gathered}
  z_{i, j} = \beta_{0, i} + B_{i}(t_{i, j})\boldsymbol{\zeta}_{i} + \varepsilon_{i, j} \\
  \beta_{0, i} \sim \text{N}(0, 1^2), \,\, \varepsilon_{i, j} \sim t_{5}(0, \omega), \,\,  \omega \sim \text{N}_{+}(0, 1^2).
\end{gathered}
\end{equation}
For the spline basis coefficients $\boldsymbol{\zeta}_{i}$, when $k = 1$ we set $\zeta_{i, 1} \sim \text{N}(0, 0.5^2)$, and for $k = 2, \ldots, 10$ we employ a random-walk smoothing prior[^smoothing] $\zeta_{i, k} \sim \text{N}(\zeta_{i, k - 1}, 0.5^2)$.

The event time $T_{i}$ is defined as the solution to the following optimisation problem
\begin{equation}
  T_{i} = \min_{t} \left\{
    \tau_{i} = \beta_{0, i} + B_{i}(t)\boldsymbol{\zeta}_{i}
    \mid
    t \in [\max(0, \min(\boldsymbol{t_{i}})), \max(\boldsymbol{t_{i}})]
  \right\},
  \label{eqn:event_time_model_def}
\end{equation}
where solutions to $\tau_{i} = \beta_{0, i} + B_{i}(t)\boldsymbol{\zeta}_{i}$ are obtained using the multiple root finder of @soetaert_rootsolve_2020.
If there are no roots, then we set $T_{i} = C_{i}$, which is equivalent to 'censoring' the observation process at $C_{i}$.

[^smoothing]: This doesn't impart as much smoothing as I thought it would, so we could reduce the inter-coefficient prior variance substantially.

#### Deriving the marginal prior for the event time

There is an importance conceptual question here:

1. Are we interested in finding the prior marginal distribution for the event time for some as yet unobserved individual? (i.e. an individual with an unknown censoring time)
1. Or are we interested in finding the (implicit) prior for $T_{i}$ for the a specific individual in our data set?

Addressing 1. requires

a. a model for the censoring process,
b. a model for the minimum and maximum observation times,
c. a model for the observation mean $\overline{z}$ and standard deviation $\hat{s}$.

This seems hard / impossible, and it is unclear to me that this is what we want.
The seemingly more relevant quantity is the prior for the specific individual $i$, which is the solution to
\begin{equation}
  T_{i} = \min_{t} \left\{
    \tau_{i} = \beta_{0, i} + B_{i}(t)\boldsymbol{\zeta}_{i}
    \mid
    t \in [\max(0, \min(\boldsymbol{t_{i}})), \max(\boldsymbol{t_{i}})]
  \right\},
\end{equation}
under the prior distribution for $\beta_{0, i}$ and $\boldsymbol{\zeta}_{i}$.
We define $\phi_{1 \cap 2} = (T_{1}, \ldots, T_{N})$, which implies $\pd_{1}(\phi_{1 \cap 2}) = \prod_{i = 1}^{N}\pd_{1}(T_{i})$.
Note that $\pd_{1}(T_{i})$ under scenario 2 implicitly conditions on each individual's censoring time, as well as the range, mean, and standard deviation of the P/F data.
The analytic form of $\pd_{1}(T_{i})$ is not available.
Instead, I think we should scale the samples of $T_{i}$ by dividing by $C_{i}$ so that they lie in $[0, 1]$, then fit a mixture of a point mass at $1$ and a beta
distribution (possibly a mixture of two betas?).
Fitting a KDE to samples from such a mixture seems unwise.

To align the notation of \eqref{eqn:event_time_model_def} with the melding notation, we define $Y_{1} = (\{\boldsymbol{z}_{i}, \boldsymbol{t}_{i}\}_{i = 1}^{N})$ and $\psi_{1} = (\{\beta_{0, i}, \boldsymbol{\zeta}_{i}\}_{i = 1}^{N}, \omega)$.

## Cumulative fluid model (piecewise linear) $\pd_{3}$

Each individual has $l = 1, \ldots, L_{i}$ 24-hourly fluid balance observations[^fluidobs], which are used to compute the cumulative fluid balance data $x_{i, l}$ with with $\boldsymbol{x}_{i} = (x_{i, 1}, \ldots, x_{i, L_{i}})$.
These data are 'observed' at times $u_{i, l}$ with $\boldsymbol{u}_{i} = (u_{i, 1}, \ldots, u_{i, L_{i}})$.
We assume a piecewise linear model for the cumulative fluid balance data.
This model is linear with slope $\eta_{1, i}^{b}$ before the breakpoint at time $\kappa_{i}$, and linear with slope $\eta_{1, i}^{a}$ after the breakpoint.
Mathematically,
\begin{equation}
\begin{gathered}
  x_{i, l} = \eta_{0, i} + \eta^{b}_{1, i}(u_{i, l} - \kappa_{i})\boldsymbol{1}_{\{u_{i, l} < \kappa_{i}\}} + \eta^{a}_{1, i}(u_{i, l} - \kappa_{i})\boldsymbol{1}_{\{u_{i, l} \geq \kappa_{i}\}} + \epsilon_{i, l} \\
  \pd(\eta_{0, i}) \propto c, \,\, \eta^{b}_{1, i} \sim \text{N}(5000, 1000^2), \,\, \eta^{a}_{1, i} \sim \text{N}(5000, 1000^2), \\
  \epsilon_{i, l} \sim \text{N}(0, \sigma^{2}_{x}),  \,\, \sigma_{x} \sim \text{N}_{+}(0, 500^2).
\end{gathered}
\end{equation}

The prior for the breakpoint $\kappa_{i}$ is derived using the following steps.
Define $u_{i, (1)} = \min(\boldsymbol{u}_{i})$ and $u_{i, (n)} = \max(\boldsymbol{u}_{i})$, with $r_{i} = u_{i, (n)} - u_{i, (1)}$.
We reparameterise the breakpoint by noting that $\kappa_{i} = \kappa^{\text{raw}}_{i}r_{i} + u_{i, (1)}$, where $\kappa^{\text{raw}} \in [0, 1]$.
We then set $\kappa^{\text{raw}}_{i} \sim \text{Beta}(5, 5)$, to regularise the breakpoint towards the middle of each individual's stay in ICU.
This is crucial when there is no evidence of a breakpoint in the data.
In such cases the posterior for $\kappa_{i}$ is almost uniform over the time spent in ICU, and the MCMC sampler tends gets stuck at values of $\kappa_{i}$ close to $0$ or $C_{i}$.
We also adopt a flat, improper prior for $\eta_{0, i}$ as a reasonable prior should depend on the length of stay -- because $\eta_{0, i}$ is the cumulative fluid balance at $\kappa_{i}$ -- and I haven't figured out how to impose or justify such a prior.

We now define $m_{i}(t) = \eta_{0, i} + \eta^{b}_{1, i}(t - \kappa_{i})\boldsymbol{1}_{\{t < \kappa_{i}\}} + \eta^{a}_{1, i}(t - \kappa_{i})\boldsymbol{1}_{\{t \geq \kappa_{i}\}}$, and $\phi_{2 \cap 3} = \left(\{\eta^{b}_{1, i}, \eta^{a}_{1, i}, \kappa_{i}\}_{i = 1}^{N}\right)$.
Note that we have explicit, analytic priors for the components of $\phi_{2 \cap 3}$.
Hence,
\begin{equation}
  \pd_{3}(\phi_{2 \cap 3}) = \prod_{i = 1}^{N} \pd(\eta^{b}_{1, i}) \pd(\eta^{a}_{1, i}) \pd(\kappa_{i}),
\end{equation}
where
\begin{equation}
  \pd(\kappa_{i}) = \pd_{\kappa^{\text{raw}}_{i}}(\frac{\kappa_{i} - u_{i, (1)}}{r_{i}}) \frac{1}{r_{i}}
\end{equation}
by the change of variables formula.

To completely align with our melding notation define $Y_{3} = (\{\boldsymbol{x}_{i}, \boldsymbol{u}_{i}\}_{i = 1}^{N})$ and $\psi_{3} = (\{\eta_{0, i}\}_{i = 1}^{N}, \sigma^{2}_{x})$.

[^fluidobs]: How these are derived from the raw fluid data is detail for the appendix. The fluid times are the average of the non-zero input/output event chart-times.

## Survival model $\pd_{2}$

- _Usually hazard functions are written in terms of arbitrary time $t$, but only evaluated at the finite set of times observed in the data. Decide if continuing this convention is better here, or is it better to be clear that $t = T_{i}$ from the outset_.

We adopt a Weibull model for the event times, with shape parameter $\gamma$.
All individuals have $b = 1, \ldots, B$ baseline (time invariant) covariates $w_{i, b}$ with $\boldsymbol{w}_{i} = (1, w_{i, 1}, \ldots, w_{i, B})$(i.e. including an intercept term), and coefficient $\theta \in \mathbb{R}^{B + 1}$.
The hazard is assumed to be affected by the rate of fluid intake, and the strength of this relationship is captured by $\alpha$.
Hence, the hazard is
\begin{gather}
  h_{i}(t) = \gamma t^{\gamma - 1} \exp\left\{\boldsymbol{w}_{i}\theta + \alpha \frac{\partial}{\partial t} m_{i}(t)\right\} \\
  \frac{\partial}{\partial t} m_{i}(t) = \eta^{b}_{1, i}\boldsymbol{1}_{\{t < \kappa_{i}\}} + \eta^{a}_{1, i}\boldsymbol{1}_{\{t \geq \kappa_{i}\}}.
\end{gather}
The cumulative hazard $H_{i}(t)$ is, for $t > \kappa_{i}$,
\begin{equation}
  H_{i}(t)
  = \int_{0}^{t} h_{i}(u) \text{d}u
  = \exp\{\boldsymbol{w}_{i}\theta\}
    \left[
      \exp\left\{
        \alpha \eta^{b}_{1, i}
      \right\}
      \kappa_{i}^{\gamma}
      +
      \exp\left\{
        \alpha \eta^{a}_{1, i}
      \right\}
      (t^{\gamma} - \kappa_{i}^{\gamma})
    \right],
\end{equation}
and for $t < \kappa_{i}$
\begin{equation}
  H_{i}(t)
  = \int_{0}^{t} h_{i}(u) \text{d}u
  = t_{i}^{\gamma} \exp\{\boldsymbol{w}_{i}\theta + \alpha \eta^{b}_{1, i}\}.
\end{equation}
The survival probability is $S_{i}(t) = \exp\{-H_{i}(t)\}$.

Given an individual's censoring time $C_{i} > 0$, an event time $T_{i}$ is uncensored if it occurs before the censoring time $T_{i} < C_{i}$.
In this case we set the censoring indicator $\delta_{i} = 1$.
If an individual is right censored then $T_{i} = C_{i}$ and $\delta_{i} = 0$.
The submodel is
\begin{equation}
\begin{gathered}
  p(T_{i} \mid C_{i}) = h_{i}(T_{i})^{\delta_{i}} S_{i}(T_{i}) \\
  \gamma \sim \text{N}_{+}(0, 1^2), \, \,
  \theta_{1} \sim \text{N}(\hat{E}, 1^2), \, \,
  \theta \setminus \theta_{1} \sim \text{N}(0, \boldsymbol{I}_{B}), \, \,
  \alpha \sim \text{N}(0, 1^2),
  \label{eqn:surv-submodel-def}
\end{gathered}
\end{equation}
where $\hat{E}$ is the log of the crude event rate [@brilleman_bayesian_2020], and $\boldsymbol{I}_{B}$ is the $B \times B$ identity matrix.

#### Deriving \eqref{eqn:surv-submodel-def} from a competing risks perspective

Patients who expire or are discharged are not actually censored.
Instead, they experience the competing, non-independent event of death/discharge.

Suppose that each individual $i$ experiences one of $d_{i} = 1, 2$ competing risks.
We observe $\{T_{i}, d_{i}\}$, where $d_{i} = 1$ indicates that individual $i$ experienced respiratory failure at time $T_{i}$.
If $d_{i} = 2$ then individual $i$ expired or was discharged at time $T_{i}$, noting that this event must occur at time $C_{i}$.
Each cause-specific hazard has parameters $\theta_{d_{i}}$ and we denote the hazard $h_{i, d_{i}}(t \mid \theta_{d_{i}}, \boldsymbol{w}_{i})$.
Denote $\boldsymbol{\theta} = (\theta_{1}, \theta_{2})$ and assume only one such event can occur at a time so that
\begin{gather}
  h_{i}(T_{i} \mid \boldsymbol{\theta}, \boldsymbol{w}_{i}) = \sum_{d_{i} \in \{1, 2\}} h_{i, d_{i}}(T_{i} \mid \theta_{d_{i}}, \boldsymbol{w}_{i}), \\
  \begin{aligned}
  H_{i}(T_{i} \mid \boldsymbol{\theta}, \boldsymbol{w}_{i})
    &= \int_{0}^{T_{i}} \sum_{d_{i} \in \{1, 2\}} h_{i, d_{i}}(u \mid \theta_{d_{i}}, \boldsymbol{w}_{i}) \text{d}u \\
    &= \sum_{d_{i} \in \{1, 2\}} \int_{0}^{T_{i}} h_{i, d_{i}}(u \mid \theta_{d_{i}}, \boldsymbol{w}_{i}) \text{d}u \\
    &= \sum_{d_{i} \in \{1, 2\}} H_{i, d_{i}}(T_{i} \mid \theta_{d_{i}}, \boldsymbol{w}_{i}),
  \end{aligned} \\
  S_{i}(T_{i} \mid \boldsymbol{\theta}, \boldsymbol{w}_{i})
    = \exp\left\{-H_{i}(T_{i} \mid \boldsymbol{\theta}, \boldsymbol{w}_{i})\right\}
    = \exp\left\{-\sum_{d_{i} \in \{1, 2\}} H_{i, d_{i}}(T_{i} \mid \theta_{d_{i}}, \boldsymbol{w}_{i})\right\}.
\end{gather}
As per Equation (8.8) in @kalbfleisch_statistical_2002 the likelihood function for a specific individual is
\begin{align*}
  \pd(T_{i}, d_{i} \mid \boldsymbol{\theta}, \boldsymbol{w}_{i})
    &= h_{i, d_{i}}(T_{i} \mid \theta_{d_{i}}, \boldsymbol{w}_{i}) S_{i}(T_{i} \mid \boldsymbol{\theta}, \boldsymbol{w}_{i}) \\
    &= h_{i, d_{i}}(T_{i} \mid \theta_{d_{i}}, \boldsymbol{w}_{i}) \exp\left\{-\sum_{d_{i} \in \{1, 2\}} H_{i, d_{i}}(T_{i} \mid \theta_{d_{i}}, \boldsymbol{w}_{i})\right\}.
\end{align*}

It is now necessary to make the following assumptions:

- That there are no shared elements in $\theta_{1}$ and $\theta_{2}$ and they are a priori independent.
- That $\theta_{2}$ is not of interest, i.e. we wish to integrate/marginalise $\theta_{2}$ out of the likelihood.

The joint model (given covariates $\boldsymbol{w}_{i}$) is

\begin{equation}
  \pd(T_{i}, d_{i}, \boldsymbol{\theta} \mid \boldsymbol{w}_{i}) =
    \pd(T_{i}, d_{i} \mid \boldsymbol{\theta}, \boldsymbol{w}_{i})\pd(\boldsymbol{\theta}).
\end{equation}

We are interested in the following marginal

\begin{equation}
  \pd(T_{i}, d_{i}, \theta_{1} \mid \boldsymbol{w}_{i})
  = \int \pd(T_{i}, d_{i}, \boldsymbol{\theta} \mid \boldsymbol{w}_{i}) \text{d}\theta_{2}
  = \int h_{i, d_{i}}(T_{i} \mid \theta_{d_{i}}, \boldsymbol{w}_{i}) S_{i}(T_{i} \mid \boldsymbol{\theta}, \boldsymbol{w}_{i}) \pd(\theta_{1}) \pd(\theta_{2}) \text{d}\theta_{2}.
\end{equation}
If $d_{i} = 1$
\begin{equation}
  \pd(T_{i}, d_{i}, \theta_{1} \mid \boldsymbol{w}_{i})
  = h_{i, 1}(T_{i} \mid \theta_{1}, \boldsymbol{w}_{i}) S_{i, 1}(T_{i} \mid \theta_{1}, \boldsymbol{w}_{i}) \pd(\theta_{1}) \int S_{i, 2}(T_{i} \mid \theta_{2}, \boldsymbol{w}_{i}) \pd(\theta_{2}) \text{d} \theta_{2},
  \label{eqn:competing-risks-deriv-one}
\end{equation}
and if $d_{i} = 2$
\begin{equation}
  \pd(T_{i}, d_{i}, \theta_{1} \mid \boldsymbol{w}_{i})
  = S_{i, 1}(T_{i} \mid \theta_{1}, \boldsymbol{w}_{i}) \pd(\theta_{1}) \int h_{i, 2}(T_{i} \mid \theta_{2}, \boldsymbol{w}_{i}) S_{i, 2}(T_{i} \mid \theta_{2}, \boldsymbol{w}_{i}) \pd(\theta_{2}) \text{d} \theta_{2}.
  \label{eqn:competing-risks-deriv-two}
\end{equation}
The standard survival analysis setting considers $T_{i}$ as data.
Thus the integrals in \eqref{eqn:competing-risks-deriv-one} and \eqref{eqn:competing-risks-deriv-two} are constants that do not depend on the parameters of interest, and can be ignored in the likelihood.
The remaining components of \eqref{eqn:competing-risks-deriv-one} and \eqref{eqn:competing-risks-deriv-two} is the likelihood obtained by considering all non $d_{i} = 1$ events as censored.
However, in our case $T_{i}$ is a parameter, and hence the the integrals are non-ignorable functions of $T_{i}$.

- If $d_{i} = 2$, then $T_{i}$ is 'fixed' at $C_{i}$.
- The type-indicator $d_{i}$ is now a parameter, where as the censoring indicator before was a function of a known censoring time and the observed event time.
- It's probably easiest to explicitly model the death/discharge event and opt for a piecewise constant hazard.
    - In this case, the likelihood is really just a mixture of an exponential distribution and a Weibull distribution, where the covariates only affect the scale parameter of the Weibull distribution.

#### Sampling the event times under the survival model

- We currently use a flat, improper prior for $\pd_{2}(\phi_{2 \cap 3})$. This will have to change when we compare forms of pooling, as it will be necessary to sample from $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$.
- My current idea for sampling $\phi_{1 \cap 2}$ under the survival model is
    - Adopt the same/similar priors for the longitudinal model parameters present in the survival submodel ($\kappa_{i}, \eta_{1, i}^{b}, \eta_{1, i}^{a}$).
    - For a generic individual, in a MH-within-Gibbs scheme
        - Sample the parameters with known prior distributions $\pd_{2}(\psi_{2}, \phi_{2 \cap 3})$,
        - Use ARMS / some other kind of MCMC to sample from $\pd_{2}(T_{i} \mid \psi_{2}, \phi_{2 \cap 3})$.
    - This process results in uncensored event times from $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$. We can post-process these samples to obtain censored versions comparable with $\pd_{1}(\phi_{1 \cap 2})$.
    - The last hurdle is estimating the density function, $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$. Fitting a parametric approximation to this density seems hard, but fitting a KDE to a mixture of a point mass and a continuous component also seems unwise. But perhaps the KDE is the best we can do?

#### Strange shape and scale of $\pd_{2}(T_{i} \mid \psi_{2}, \phi_{2 \cap 3})$

In Figure \ref{fig:prior_samples_plot}, we see that the shape of $\pd_{2}(T_{i} \mid \psi_{2}, \phi_{2 \cap 3})$ varies substantially between samples.
This makes sampling from $\pd_{2}(T_{i} \mid \psi_{2}, \phi_{2 \cap 3})$ challenging.
The interaction between the $\kappa_{i}, \alpha$, and $\eta_{1, i}^{a}$ can result in a large proportion of the prior density being very close to $\kappa_{i}$.

```{r prior_samples_plot, fig.cap = 'Unnormalised event time target conditional on other parameters: $q(T_{i} \\mid \\psi_{2}, \\phi_{2 \\cap 3})$. Note that the x-axis is logarithmically scaled, and that the y-axis varies by many orders of magnitude between plots.'}
knitr::include_graphics('../plots/mimic-example/test-event-time-prior-target.pdf')
```

# Pooling the priors

Once we have expressions or estimates of the prior marginal distributions, we need to:

- Decide what type of pooling to use (probably all of them and compare)
- Choose pooling weights, and run some kind of prior predictive check?
- Apportion the pooled prior over the stages of the multi-stage sampler, and which stage to divide by the marginals.

# Bibliography
