# what would make this a great piece of work?

## scientific-data

- If we can combine models that were otherwise not combine-able
    - This will be difficult. without specific domain knowledge on data that area currently collected/model separately, but related, we will struggle to find examples
- If the scientific insights generates from this process were novel to the application
    - Need to combine novel types of data, and have the domain expertise to interpret the output (and know what to compare them to / show improvement / something meaningful)

-> Probably requires novel data / situation

## scientific-comparison to other methods 

- if the methodology can be shown to be more general / distinct from / encapsulates other methods, and that there is some mathematical / practical advantage to doing so
- Possible comparisons
  - chain graphs
  - Sequential Bayes (with strange prior structure)
  - Group decision making / grp decision theory / group prior construction

## theory

- Demonstrably 'Bayesian' -- coherent etc
  -> Probably could heuristically argue for this, unlikely to be able to prove such things


## empirical evidence

- if the estimation process was demonstrably robust (unlikely to show that it is theoretically robust)
  - move away from KDEs / Multi-stage sampling
  - Show necessary approximations have little impact (need reference)
- if there were some computational speed up / benefit
- if it is some how 'more coherent' than an alternative that people seem to do (more easily explained)

