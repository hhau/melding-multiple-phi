<!-- This needs to go in the introduction of the thesis -->
- Note that for the acceptance probabilities to be interpretable as probabilities, they must be bounded between zero and 1. 
- To avoid clutter in the mathematics, we do not explicitly write $\alpha(\phi^{*}, \phi) = \text{min}\left(1, \frac{\pd (\phi^{*} \mid Y)}{\pd(\phi \mid Y)}\right)$ for all acceptance probability calculations.
- This never matters in practice, as acceptance probabilities are only ever compared with samples from a $\text{U}(0, 1)$ random variable, and hence if they happen to exceed 1, they were to be accepted anyway.

# Literature review + analysis 

- Massa papers (Again)
    - See if they have a good graph theory based notation
    - Think in terms of adjacency matrices / adjacencies
- Data fusion? they have some nice words for this: (data|information) (fusion|combination|integration)
- Network meta analysis
- https://arxiv.org/pdf/1810.05575.pdf ? - too specific / technical
- https://dl.acm.org/citation.cfm?id=1512927
    - "Target" here has an interesting meaning
- Probability propagation / belief propagation
    - https://link.springer.com/article/10.1007/BF01531015
    - http://www.stats.ox.ac.uk/~steffen/teaching/gm09/propag.pdf

- Ecologists really want to do this kind of thing:
    - https://esajournals.onlinelibrary.wiley.com/doi/toc/10.1002/(ISSN)1939-9170.SF-Data-Integration
    - https://www.stat.colostate.edu/~hooten/papers/pdf/Williams_etal_Ecology_2017.pdf
        - Too hard with the PDE term
    - https://www.stat.colostate.edu/~hooten/papers/pdf/Pepin_etal_EcolLetters_2017.pdf
        - Maybe? Meld over $\phi = (\theta, \sigma^2)$ if the DAG is to be believed
        - This is a good melding example, but doesn't help with the multiple phi thing
        - Might still be useful?
    - https://esajournals.onlinelibrary.wiley.com/doi/full/10.1002/ecy.2710
        - Model integration seems to be taking off
    - https://esajournals.onlinelibrary.wiley.com/doi/10.1002/ecy.2711
        - this has 5 data sources, but looks quite complicated, it would be real neat if we could do this properly? (nah, relies on some proprietary software)
    - https://esajournals.onlinelibrary.wiley.com/doi/10.1002/ecy.2714
        - Could be split into three models? Little different than I was thinking
        - Has data and BUGS code
    - https://link.springer.com/chapter/10.1007/978-1-4939-0977-3_9
    - https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/11-1881.1
    - https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/10-0052.1
        - This is an interesting critique of one specific, complex model. It is somewhat dated (conjugate analyses are less prevalent nowadays) but it still rightly critiques complex models that do not have a grounded research question in mind.
    - https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/ecy.1710
        - yet another use of the term _data fusion_

## Integrated population models

There is a huge number of examples in Ecology of _integrated population models_.
_Integrated_, in that they integrate more than one source of data and an associated model, with the overall focus being on estimating the dynamics of a _population_ (birth, death, reproduction, and migration rates) and temporal abundance (how many of them are there at a point in time.)

- https://projecteuclid.org/euclid.ba/1551949261
    - If we decide to go to BA?

- https://www.sciencedirect.com/science/article/pii/S0006320717305141?via%3Dihub
    - Figure 1 in here is _exactly_ what I was thinking of in Section \ref{arbitrary-graphs-of-models}
        - The process they describe is:
            1. Specify submodels for the data sets (ensuring they have some parameters in common)
            2. Form the joint model by multiplying the individual submodels together
            3. Estimate the join model 
        - This is in effect, melding for multiple parameters using product of experts for the pooled prior.
        - The table gives us a bunch of examples to go and look at?
    - The paper Figure 1 is based off: https://link.springer.com/article/10.1007%2Fs10336-010-0632-7
        - _Sixth, the joint likelihood of integrated population models might be developed in such a way that it explicitly accounts for the dependence among datasets, such that the assumption of independence can be relaxed._
            -  I don't think Melding specifically does this (just makes the inter model dependence explicit)
        - _Seventh, the integrated population models could be modified in such a way that integral (i.e. continuous) population models (Ellner and Rees 2006) instead of stage- or age structured (i.e. categorical) population models are used to define the link between population size and demography. This would allow the quantifying of the impact of individual continuous traits on population dynamics._ 
            - Melding can do this, but their gripe seems to be applications specific
        - _Finally, another avenue is to explore additional data types that contain demographic information and that may be linked to a population model._
            - This is application specific.
- https://onlinelibrary.wiley.com/doi/epdf/10.1111/oik.01924
    - Another very similar example
    - The fit this jointly, and note that convergence is no good for some quantities, they also note an imbalance in information quantity between data sets.
    - BUGS code: http://www.oikosjournal.org/sites/oikosjournal.org/files/appendix/oik-01924.pdf - somewhat complex.
- https://link.springer.com/content/pdf/10.1007/s13253-018-00349-9.pdf 
    - this is a statisical look at estimating IPMs using SMC, dealing with the fact that they often have latent discrete parameters
    - `4.3. IMPROVING SMC EFFICIENCY FOR INTEGRATED MODELS` is effectively an SMC version of the melding multi-stage sampler, but with tempering
    - Also a good source of examples, as they are 'pre-translated' into statistical language

- https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13110
    - Another recent, review on computational methods in integrated population models 
    - It is interesting that they see the advantage of integrated modelling as being able to better design experiments? (as well as consider more sources of information)

- https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-985X.2008.00582.x

- https://onlinelibrary.wiley.com/doi/full/10.1111/gcb.13538
    - This example seems simpler, but can't get at code + data?

<!-- This should probably be in the introduction not the examples -->
- _Q_: What are IPMs and why do ecologists use them?
- Integrated population models (IPMs) allow ecologists to combine data on a population's abundance (how many), trajectory (birth / death / immigration / emigration rates), demography (juvenile / adult / sex), and spatial location (where).
- The combination of these data allows ecologist to infer quantities that would be unidentifiable using a single source of data.
- Additionally, IPMs make the model specification task is easier; data are modelled separately from one another, and the submodels are then combined to form the IPM.
- This process is equivalent to Markov melding using product-of-experts to form the pooled prior.
 


## More thoughts on examples

- Seems to be a popular idea in Ecology, so useful as examples, but will not necessarily have the greatest impact (they are already aware they can do such a thing).
- Why reframe these models in this particular framework?
    - There is value in unifying disparate modelling frameworks. Different applied fields seem to do similar things but with different names. Advantages, practical tips, and patterns of thought are more easily shared with a common mathematical framework.
        - Justifying this requires an example from another field.
    - Having a mathematical framework may also make it easier to spot sensible extensions to models
        - Really? Maybe writing down submodels in a common notation makes it easier to spot where additional information could be incorporated?
    - (_somewhat specific to IPMs_): IPMs are currently limited to models where interacting with the joint distribution directly is possible; the sequential sampler is designed to circumvent this restriction, i.e. to enable inference in settings where evaluating the joint distribution is infeasible.
        - As the authors of one particular review article note, many ecologists are technically inclined to implement their own IPMs (although they can be done in BUGS?), tools making this easier would be valuable.
        - Finke/King/Beskos/Dellaportas SMC example still requires evaluating the joint.
            - It might be sensible to steal then notation from here


# Melded model


# The pooled prior and pooling weights

## General case

The logarithmic pooled prior for $\Nm$ models in a chain is
\input{tex-input/multiple-phi/0051-pooled-prior-overall-general.tex}

\newpage

# Model ordering and commutativity 


1. _Is this any different from melding $\pd_{1}(\phi_{1 \cap 2}, \psi_{1}, Y_{1})$ and $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3}, \psi_{2}, Y_{2})$ together first, then melding the result with $\pd_{3}(\phi_{2 \cap 3}, \psi_{3}, Y_{3})$?_
    1. If it is different, why? When are they the same, and when not?
        - @massa:lauritzen:10 note that in the case of Markov combination, this is not always true.
    1. The previous two questions assume that melding $\pd_{1}$ with $\pd_{2}$ first, then the result with $\pd_{3}$ is commutative, i.e. melding $\pd_{2}$ with $\pd_{3}$ first, then the result with $\pd_{1}$ should be identical.
        - Ignoring practical reasons why this may not be the case.
2. _Does applying this operator to 2 $\Nm = 3$ chains of models (base case) result in the same thing as applying it to $\Nm = 6$ models at once?_
    - This will depend on the relationship between the two groups of models? Assume it's a chain and check?
    - We can probably just generalise the result from (1.) / the original melding operator?
    - If we distinguish the new operator from the old one, then we should verify this.

## Applying the original Markov Melding operator twice



#### Example {-}

\input{tex-input/noncommutativity/0030-example-cond-comm.tex}

# Multi-stage sampler 1: starting with $\modelindex = 1$

Beginning with the general case, the overall target is
\input{tex-input/multi-stage-sampler/0010-melded-posterior.tex}

## Stage one

Target
\input{tex-input/multi-stage-sampler/0020-stage-one-target.tex}
This is targeted with a single MCMC proposal $\q(\phi_{1 \cap 2}^{*}, \psi_{1}^{*} \mid \phi_{1 \cap 2}, \psi_{1})$, leading to an acceptance probability of
\input{tex-input/multi-stage-sampler/0021-stage-one-acceptance-probability.tex}


## Stage two

Target
\input{tex-input/multi-stage-sampler/0030-stage-two-target.tex}
using Gibbs updates (_Should Gibbs updates use the asterisk?_)
\input{tex-input/multi-stage-sampler/0031-stage-two-gibbs-updates.tex}
These updates have acceptance probabilities 
\input{tex-input/multi-stage-sampler/0032-stage-two-acceptance-probabilities.tex}

Formally, one can update the $\psi_{1}$ samples from stage one by keeping track of the indices[^indices].

[^indices]: I need to formally think about and define the indices, we are going to refine / resample them in strange ways over many steps.

## Stage $\Nm - 1$

Target
\input{tex-input/multi-stage-sampler/0040-stage-Mminus1-target.tex}
using Gibbs updates
\input{tex-input/multi-stage-sampler/0041-stage-Mminus1-gibbs-updates.tex}
results in acceptance probabilities of
\input{tex-input/multi-stage-sampler/0042-stage-Mminus1-acceptance-probabilities.tex}

## Stage $\Nm$

- Include the $\Nm$th model, which we already have samples of $\phi_{\Nm - 1}$ for.

Target
\input{tex-input/multi-stage-sampler/0050-stage-M-target.tex}
with Gibbs updates
\input{tex-input/multi-stage-sampler/0051-stage-M-gibbs-updates.tex}
with acceptance probabilities
\input{tex-input/multi-stage-sampler/0052-stage-M-acceptance-probabilities.tex}

## Stage $\Nm + 1$

Target
\input{tex-input/multi-stage-sampler/0060-stage-Mplus1-target.tex}
with a one step update
\input{tex-input/multi-stage-sampler/0061-stage-Mplus1-update.tex}
which has an acceptance probability of
\input{tex-input/multi-stage-sampler/0062-stage-Mplus1-acceptance-probability.tex}

- This could be combined with stage $\Nm$, but pedagogically it is nice to have it as a separate stage.

\newpage

# Multi-stage sampler 2: Split and recombine

## Meet in the middle

_Rewrite for $\Nm = 3$ models, pick a consistent name_.

\input{tex-input/dc-sampler/0000-tikz-target.tex}

Choose a specific model $k$.
Recursively use this split and recombine method, or the aforementioned multi-stage sampler, to generate samples from the first set of models $\textcolor{mymidblue}{A} = \{1, \ldots, k - 1\}$, with melded joint distribution 
    $$\pd_{\text{meld}, \textcolor{mymidblue}{A}}(\phi_{1 \cap 2}, \ldots, \phi_{k - 1 \cap k}, \psi_{1}, \ldots, \psi_{k - 1}, Y_{1}, \ldots, Y_{k - 1})$$ 
and the second set $\textcolor{myredhighlight}{B} = \{k + 1, \ldots, \Nm\}$, with melded joint distribution 
    $$\pd_{\text{meld}, \textcolor{myredhighlight}{B}}(\phi_{k \cap k + 1}, \ldots, \phi_{\Nm - 1 \cap \Nm}, \psi_{k + 1}, \ldots, \psi_{\Nm}, Y_{k + 1}, \ldots, Y_{\Nm}).$$

The last step of the multi-stage sampler then targets the overall melded posterior
\input{tex-input/dc-sampler/0010-dc-final-target.tex}
with Gibbs updates
\input{tex-input/dc-sampler/0011-dc-gibbs-updates.tex}
and acceptance probabilities
\input{tex-input/dc-sampler/0012-dc-acceptance-probabilities.tex}


# Arbitrary graphs of models

- Notation: Choose model $\pd_{a}$ for initial target?
- The all models connected to $a$ are $b_{i}$ for $i = 1, \ldots, N_{b}$?
    - This quickly breaks down if things reconnect? Also what would the next layer be called $c_{i, j}$? for $j = 1, \ldots, N_{j, b}$?
- Lets look an an example DAG, we can also introduce the arrow notation for noninvertible link functions, Figure \ref{fig:example-model-graph}.

\input{tex-input/arbitrary-graphs/0010-example-model-graph.tex}

- We can come up with a sampling strategy for this, partially determined by the arrows
    - $s_{1} = \{\pd_{4}\}, s_{1}' = \{\pd_{2}\}$
        - These can occur in parallel
    - $s_{2} = \{\pd_{3}, \pd_{4}\}$
        - This can occur whilst $s_{1}$ is ongoing.
    - $s_{3} = \{\pd_{1}, \pd_{2}, \pd_{3}, \pd_{4}\}$
    - $s_{4} = \{\pd_{1}, \pd_{2}, \pd_{3}, \pd_{4}, \pd_{5}\}$

- We should the redraw the DAG such that things that could be done in parallel are on an equal level.

\input{tex-input/arbitrary-graphs/0011-example-model-graph.tex}


# Conclusion

- There are a lot of unknown self-density ratios, including many $\pd_{\modelindex}(\phi_{\modelindex - 1, \text{nu}}, \phi_{\modelindex, \text{nu}}) \mathop{/} \pd_{\modelindex}(\phi_{\modelindex - 1, \text{de}}, \phi_{\modelindex, \text{de}})$ terms.
    - In the case where $\phi_{\modelindex - 1}$ and $\phi_{\modelindex}$ are both one dimensional, this is already a four-dimensional problem.
    - We can reframe this as an advantage, as estimating $\pd_{\text{pool}}(\phi_{1 \cap 2}, \ldots,\phi_{\Nm - 1})$ is potentially a series of lower dimensional estimation problems, which is easier than one estimation problem in a larger dimension?

- Just take parametric approximations and move on with our lives lol (or fit mixtures using heavyish tails)



