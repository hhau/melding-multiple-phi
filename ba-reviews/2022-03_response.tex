% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode,backref,colorlinks=true}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  10pt,
  a4paper,
]{article}
\usepackage{amsmath,amssymb}
\usepackage[]{tgpagella}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Response to Reviewers},
  pdfauthor={Andrew A. Manderson and Robert J. B. Goudie},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=2.25cm]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\usepackage{amsmath,mathtools}
% I always seem to need tikz for something
\usepackage{tikz}
\usetikzlibrary{positioning, shapes, intersections, through, backgrounds, fit, decorations.pathmorphing, angles, quotes}
\usepackage{lineno}
% \linenumbers


\makeatletter
\@ifclassloaded{imsart}{}{
\usepackage{setspace}
\onehalfspacing
}
\makeatother

\usepackage{bbm}

\usepackage{enumitem}
\usepackage{relsize}
\usepackage{placeins}

% required for landscape pages. beware, they back the build very slow.
\usepackage{pdflscape}

% table - `gt' package uses these, often unimportant
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{caption}

\usepackage{color}
\definecolor{myredhighlight}{RGB}{180, 15, 32}
\definecolor{mydarkblue}{RGB}{0, 33, 79}
\definecolor{mymidblue}{RGB}{44, 127, 184}
\definecolor{mylightblue}{RGB}{166, 233, 255}
\definecolor{mygrey}{RGB}{68, 68, 68}

\usepackage{colortbl}

\newcommand{\semitransp}[2][35]{\color{fg!#1}#2}

\setcounter{secnumdepth}{3}

\let\Oldcap\cap
\renewcommand{\cap}{\mathrel{\mathsmaller{\Oldcap}}}

\renewcommand{\floatpagefraction}{0.95}
\renewcommand{\topfraction}{0.95}
\renewcommand{\bottomfraction}{0.95}
\renewcommand{\textfraction}{0.05}

% pd stands for: probability distribution and is useful to distringuish
% marignals for probabilities specifically p(p_{1}) and the like.
\newcommand{\pd}{\text{p}}
\newcommand{\q}{\text{q}}
\newcommand{\w}{\text{w}}
\newcommand{\pdr}{\text{r}}
\newcommand{\pdrh}{\hat{\text{r}}}

% melding
\newcommand{\ppoolphi}{\pd_{\text{pool}}(\phi)}
\newcommand{\pmeld}{\pd_{\text{meld}}}

% the q(x)w(x), "weighted target" density 
% for the moment I'm going to call it s(x), as that is the next letter of the 
% alphabet. Can change it later
\newcommand{\s}{\text{s}}
% direct density estimate - replaces lambda.
\newcommand{\ddest}{\text{s}}
% target weighting function
\newcommand{\tarw}{\text{u}}

% constants - usually sizes of things
\newcommand{\Nx}{N}
\newcommand{\Nnu}{\text{N}_{\text{nu}}}
\newcommand{\Nde}{\text{N}_{\text{de}}}
\newcommand{\Nmc}{\text{N}_{\text{mc}}}
\newcommand{\Nw}{W}
\newcommand{\Nm}{M}
\newcommand{\Ns}{S}
\newcommand{\Np}{P}

% locales - could switch to x and x'
\newcommand{\xnu}{x_{\text{nu}}}
\newcommand{\xde}{x_{\text{de}}}
\newcommand{\phinu}{\phi_{\text{nu}}}
\newcommand{\phide}{\phi_{\text{de}}}

% sugiyama stuff
\newcommand{\pdnu}{\pd_{\text{nu}}}
\newcommand{\pdde}{\pd_{\text{de}}}

% indices 
\newcommand{\wfindex}{w}
\newcommand{\sampleindex}{n}
\newcommand{\modelindex}{m}
\newcommand{\stageindex}{s}
\newcommand{\phiindex}{p}

% independence symbol
\newcommand{\indep}{\perp\!\!\!\perp}
\newcommand{\setcomp}{\mathsf{c}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]

\DeclareMathOperator*{\argmin}{arg\,min}

% ARDS example in text commands
\newcommand{\paoii}{PaO\textsubscript{2}}
\newcommand{\fioii}{FiO\textsubscript{2}}
\newcommand{\spoii}{SpO\textsubscript{2}}
\newcommand{\pfratio}{\paoii/\fioii}
\newcommand{\sfratio}{\spoii/\fioii}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{Response to Reviewers}
\author{Andrew A. Manderson and Robert J. B. Goudie}
\date{02 May, 2022}

\begin{document}
\maketitle

\hypertarget{reviewer-1}{%
\section*{Reviewer 1}\label{reviewer-1}}
\addcontentsline{toc}{section}{Reviewer 1}

\begin{quote}
\(\hookrightarrow\)\textbf{R1}: \emph{My main suggestion is for the
authors to shorten the manuscript by moving one of the examples to an
appendix and instead add a bit more detail about how the melding
actually works for readers who may not have familiarity with the
previous literature on the topic (including the authors' prior paper on
it). I appreciate both examples in the manuscript, but it might be
better to include details about when the pooling results in inference
that is exact versus approximate, for example. There are many choices
one must make to implement these methods for fitting models and I think
it would help to provide some additional details about the approximation
that occurs and the actual algorithms that are used (multi-stage) to fit
the models using this approach which don't currently appear until the
appendix.}
\end{quote}

We thank the reviewer for the kind comments. We will respond in reverse
order to the points raised by Reviewer 1.

We agree that there are many choices to make when implementing chained
Markov melding, but we delineate between choices specific to chained
Markov melding and those that must be made when fitting any model. We
wish to include in the main text the choices that we feel will
\emph{always} be important in applications of chained Markov melding,
with related, but ultimately example-specific, choices included in the
appendix. To this point we have clarified the purposes of the appendices
in the text, and explicitly stated the choices specific to chained
Markov melding that users must make. Our changes are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Adding a sentence to the end of paragraph 1 of the conclusion to that
  reads:

  ``\emph{We also present the choices, and their impacts, that users of
  chained Markov melding must make which include: the choice of pooling
  function, and where required the pooling weights; the choice of
  posterior sampler and the design thereof, including the apportionment
  of the pooled prior over the stages and stage-specific MCMC
  techniques.}''
\item
  Emphasising in the text and within the appendix that the
  individual-at-a-time sampler is only possible due to the conditional
  independence between individuals in the posterior. Appendix K
  establishes the validity of our sampler, but the argument is specific
  to the submodels in the second example (though other submodels may
  have such posterior conditional independences). The general
  applicability of the individual-at-a-time sampler is low, so including
  it in the main text seems unnecessary and likely to confuse the
  reader. Specifically, we have added a sentence in Section 5.5 that
  reads:

  ``\emph{This is possible due to the conditional independence between
  individuals in the posterior, and Appendix K contains the details of
  this scheme.}''

  and modified subsection ``sub-step 1'' of Appendix K to include:

  ``\emph{The model, detailed in Section 5.1, uses the conditional
  independence between individuals to factorise such that
  \textellipsis}''.
\item
  Noting in the main text that Appendix B is provided only for
  completeness. We do not use the sequential sampler in either of our
  examples. The footnote on page 13 now reads:

  ``\emph{For completeness, Appendix B describes such a sequential MCMC
  sampler. We do not use the sequential sampler in this paper.}''
\end{enumerate}

Furthermore, we think that Appendices E, G, and H, covering prior
specification and prior marginal estimation, are important but
ultimately routine aspects of Bayesian modelling. Appendices D and I are
decisions specific to the data we consider, and would be made as part of
any analysis of observational data (and would often go unreported), or
would be specified in an analysis plan.

We are unsure of the meaning of the comment describing pooling as
producing inference that is exact or approximate. When all prior
marginal densities are known analytically, the pooling function produces
an analytic expression proportional to
\(\pd_{\text{pool}}(\boldsymbol{\phi})\) -- there is no approximation
error here. If one or more of the prior marginal densities is unknown,
then we suggest approximating it with a standard distribution or using
kernel density estimation. Regardless, the pooling function does not
introduce any approximation in addition to that of the prior marginal
density estimate. If by `exact' the reviewer is instead referring to
situations where the chained Markov melded model is the same as the
original joint model, then we wish to point our that a suitable joint
model must exist in the first place (see our response to Reviewer 2 for
further details). Our first example is one such situation, and we have
added the following to the start of Section 4:

\begin{itemize}
\tightlist
\item
  ``\emph{This example is particularly interesting to us as, for a
  certain choice of pooling function and pooling weights, the chained
  Markov melded model and the IPM are identical. This coincidence allows
  us to use the posterior from the IPM as a benchmark for our
  multi-stage sampler.}''
\end{itemize}

and the following (new in italic) to Section 4.5:

\begin{itemize}
\tightlist
\item
  ``We also use logarithmic pooling with
  \(\lambda = (\frac{1}{2}, \frac{1}{2}, \frac{1}{2})\), which is
  denoted \(\pd_{\text{meld, log}}\) \emph{and results in the chained
  melded model being identical to the IPM.}''
\end{itemize}

To address Reviewer 1's first comment, we appreciate the inclination
towards a shorter manuscript, but ultimately feel tied to including both
examples in the main text. As Reviewer 2 notes, the first example is
intentionally illustrative -- we have split an existing joint model to
make clear, in a simpler setting, the chained Markov melding steps and
proposed computational tools, whilst possessing a baseline result for
comparison. This example is also intended to reassure the reader that
our proposed multi-stage sampler can produce accurate results. Whilst we
find this example informative, it is ultimately insufficiently
compelling to justify the methodology. The second example is much more
compelling for the methodology, and as Reviewer 2 notes it is the
example's complexity that motivates the methodology. If such complex
submodels were not necessary we might be able to immediately conceive of
a joint model for all sources of data. Without the second example we
feel some readers will be left wondering what use, if any, there might
be for our method. Finally, moving the first example to the appendix
would save only 4 pages, so information currently in the appendix would
remain there in either case.

We hope that these points, in addition to addressing the reviewers other
comments, sufficiently convince the reviewer of the need for both
examples.

\begin{quote}
\(\hookrightarrow\)\textbf{R1}: \emph{I also have a number of minor
typographical suggestions:}
\end{quote}

We thank the reviewer for the suggestions and have adopted them in the
revised version.

\hypertarget{reviewer-2}{%
\section*{Reviewer 2}\label{reviewer-2}}
\addcontentsline{toc}{section}{Reviewer 2}

We thank the reviewer for the kind comments.

\begin{quote}
\(\hookrightarrow\)\textbf{R2}: \emph{(2) I would like the authors to
explain why one would not simply ensure that all sub-models can use the
same prior, so that we are back in the ``Markov combination'' setting of
Equation 1 (in which case no ``pooled'' priors need to be constructed).
It seems to me that a principled Bayesian approach would always seek to
formulate a single prior distribution over all parameters in the model.}
\end{quote}

We agree with this principle -- it does seem desirable to have the same
prior for the same quantity in different models. But there is a tension
between having the submodels be complete and contained, meaning they
could be specified and understood independently of the chained melded
model, and having the same prior for all common quantities under all
submodels.

Our starting point for our methodology is multiple complete submodels,
which may be specified by separate practitioners with distinct priors
for the submodels they are each concerned with. If these practitioners
could be tasked with specifying a single prior for the joint/chained
Markov melding model, then the fact that one of the common quantities is
a complex, noninvertible function of other submodel parameters poses a
significant technical challenge to specifying such a prior. In our
second example, this would involve carefully and simultaneously
specifying the prior for the spline coefficients in \(\pd_{1}\) and the
prior for the piecewise-linear regression parameters in \(\pd_{3}\),
such that \(\pd_{1}(\phi_{1 \cap 2}) = \pd_{2}(\phi_{1 \cap 2})\),
\(\pd_{2}(\phi_{2 \cap 3}) = \pd_{3}(\phi_{2 \cap 3})\), and
\(\pd_{1}(\phi_{1 \cap 2})\pd_{3}(\phi_{2 \cap 3}) = \pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})\).
There are no guarantees that such a choice of prior exists. In our
experience there are typically many possible priors that have a specific
prior predictive distribution for a quantity that is a noninvertible
transformation of the parameters. Even if such a prior does
theoretically exist it is unclear how we might actually specify such a
prior.

From our starting point of multiple submodel priors, we then ask
ourselves ``how can we reformulate the problem of chained submodel
combination to be as similar as possible to Markov combination?'' The
goal -- implicit in this question, and as the reviewer suggests -- is to
acquire a common prior for \(\boldsymbol{\phi}\). Indeed, one motivation
for marginal replacement in Goudie \emph{et al.}
(\protect\hyperlink{ref-goudie_joining_2019}{2019}) is to make Markov
combination more widely applicable, and the marginal replacement
procedure we propose in Section 2.1 shares this intention. Consider an
alternative approach where we choose exactly one of the submodel priors
for use in the melded model. This is dictatorial pooling, and thus
Markov combination is the special case of Markov melding with
dictatorial pooling where all submodel prior marginals are identical.
For chained Markov melding this is unappealing for the reasons we
discuss in the dictatorial pooling subsection of Section 2.2.
Specifically, that choosing one prior does not ``span'' all the
quantities in \(\boldsymbol{\phi}\). Our dictatorial pooling proposal
for chained Markov melding is our proposal for a joint model as similar
to Markov combination as possible in the chained model setting. Our
logarithmic and linear proposals are transparent methods for obtaining a
single common prior \(\pd_{\text{pool}}(\boldsymbol{\phi})\) in
situations where the dictatorially pooled prior is unacceptable.

Finally, whilst we would like to undertake a fully principled approach
akin to the reviewers suggestion, in some applications this can be too
lofty a goal. Often the number of information sources are too numerous,
with some having standard models and others not, and the
computational/time constraints are so apparent that to start building a
suitable joint model is infeasible. Our aim is to make it possible to be
more Bayesian. That is, we would like to start incorporating uncertainty
from many information sources in a more transparent fashion than the
alternative of 1) fixing a common quantity to a point estimate or 2)
specifying a Gaussian distribution for said quantity (e.g.~Section 4.2.4
of \protect\hyperlink{ref-nicholson_interoperability_2021}{Nicholson
\emph{et al.}, 2021}). We posit that the construction of a complex joint
models by combining smaller, easier to understand submodels results in a
better quantification of uncertainty (whilst also retaining the ability
to specify, possibly fit, and interrogate the submodels before combining
them).

\par

\noindent\hrulefill

\par

We address points (3) and (4) simultaneously.

\begin{quote}
\(\hookrightarrow\)\textbf{R2}: \emph{(3) The proposed methodology
appears to perform well in the integrated-population-model (IPM)
example. But, as the authors mention, this is just for illustration
since the joint posterior distribution in this model can be easily and
cheaply approximated using a single MCMC chain via standard software
packages.} \emph{The model in Section 5 appears to be realistically
complex. It is great to see such non-toy examples in a methodological
paper. However, the example is almost too complex: I am finding it
difficult to understand how well (or poorly) the proposed methodology
performs here. It would be really good to have benchmark results for the
joint model without the bias induced by Markov melding (i.e.~in the same
way as these are shown for the IPM example). I would expect that such
results are be attainable using a sequential Monte Carlo sampler.}
\end{quote}

\begin{quote}
\(\hookrightarrow\)\textbf{R2}: \emph{(4) If benchmark results cannot be
obtained for the model from Section 5, this would also be interesting
and mentioning this would make the paper much stronger. Because when
reading the paper, I did not see an explanation of why the model could
not be estimated without Markov melding (and without the bias that this
can introduce).}
\end{quote}

To obtain benchmark results there must exist 1) a comparable joint model
and 2) a ``default'' method for sampling/approximating the posterior of
this model.

With respect to the first prerequisite, the premise for the respiratory
failure (RF) example, and indeed the methodology, is that there are
situations in which it is prohibitively difficult to specify a suitable
joint model. Without such a joint model there is no baseline against
which we could declare a model biased. Additionally, the joint model
formed by multiplying the individuals submodels is a form of chained
Markov melding (using product-of-experts pooling); to use it as a
baseline would be circular. Note that we use ``bias'' here to refer to,
for example, the difference between \(\pd_{\text{meld, PoE}}\) and
\(\pd_{\text{IPM}}\) in the IPM example for \(\alpha_{0}\) and
\(\alpha_{2}\) (see Figure 5). That is, bias arising due to the use of
different joint models.

This kind of bias is not an immediate consequence of chained Markov
melding. As noted in the text for the IPM example, and in response to
Reviewer 1, the IPM and the chained model using log-pooling with
\(\lambda = (\frac{1}{2}, \frac{1}{2}, \frac{1}{2})\) are precisely the
same joint model, so no bias of this type is introduced by chained
Markov melding in that example.

Another type of bias arises due to using only finitely many samples in
estimating the prior marginal distributions
\(\hat{\pd}_{\modelindex}(\phi_{\modelindex})\). However, should these
prior marginals be known or PoE pooling used, such estimates do not
appear in the chained melded model and so finite sample bias is of no
concern. Moreover, any joint model partially comprised of finite sample
estimates will be affected by such biases, it is not unique to chained
Markov melding.

It is not clear to us which of these two types of bias, or perhaps
another type altogether, the referee is referring to. As such, we find
the meaning of `bias induced by Markov melding' difficult to determine
in this comment and it is unclear to us what joint model the reviewer
wishes to target.

For the second prerequisite, there are a number of additional
difficulties to do with implementing such an SMC sampler (once a
target/joint model has been decided upon):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Simultaneously evaluating all the terms in the chained melded model is
  necessary and computationally challenging in a SMC/MCMC environment.
  This is a secondary motivation for the sampler, as complex evidence
  synthesis / joint models often cannot be readily evaluated in this
  manner (see, for example, the models in
  \protect\hyperlink{ref-nicholson_interoperability_2021}{Nicholson
  \emph{et al.}, 2021}).

  Avoiding concurrently evaluating all submodels also enables the reuse
  of existing software, minimising the need for custom submodel and/or
  sampler implementations (and the effort the construction/tuning of
  them entails). We see this as an advantage of our multi-stage
  estimation method, as it reduces the effort required to be ``more
  Bayesian'' and better quantify uncertainty. We state this in both the
  introduction and in Section 4.6, and have added additional text to the
  first paragraph of Section 3.

  One complication of this variety in the second example is the
  calculation of
  \(\phi_{1 \cap 2} = (f(\chi_{1 \cap 2, 1}), \ldots, f(\chi_{1 \cap 2, N}))\).
  The mathematics belies much complexity, specifically because we rely
  on a multiple root finder. Implementing this within an HMC, or SMC
  with HMC refreshment, setting involves massively increasing the number
  of times this problem must be solved. Using our multi-stage sampler
  turns this into an embarrassingly parallel, post-stage-one processing
  problem.
\item
  Our preoccupation with HMC is because the example depends on a
  relatively high number (\(5 \times 10^{4}\)) of high-quality samples
  from \(\pd_{1}(\phi_{1 \cap 2}, \psi_{1} \mid Y_{1})\), which is
  \(N(2 + 10) = 444\)-dimensional and highly correlated within each of
  the 12-dimensional individual subposteriors (see Figure
  \ref{fig:coef_pairs} at the end of this document). This is made
  possible by the efficient dynamic HMC implementation within
  \texttt{Stan}.
\item
  There are no sufficiently flexible off the shelf SMC packages.
  \texttt{NIMBLE}
  (\protect\hyperlink{ref-michaud_sequential_2020}{Michaud \emph{et
  al.}, 2020}) does not support either the B-spline basis function nor
  multiple-root finder, and whilst one could in theory recode both in
  \texttt{Rcpp} to make use of \texttt{RcppSMC}
  (\protect\hyperlink{ref-eddelbuettel_rcppsmc_2021}{Eddelbuettel
  \emph{et al.}, 2021};
  \protect\hyperlink{ref-johansen_smctc_2009}{Johansen, 2009}), this
  would be an enormous undertaking. We also point out the difficultly in
  implementing an SMC sampler for the considerably simpler first example
  encountered by Finke \emph{et al.}
  (\protect\hyperlink{ref-finke_efficient_2019}{2019}) (with details
  discussed in the online appendix). Tuning these types of samplers is
  nontrivial (\protect\hyperlink{ref-buchholz_adaptive_2021}{Buchholz
  \emph{et al.}, 2021}).
\item
  A complete set of numerical and visual diagnostics for the multistage
  samplers are contained in the online repository, should there be any
  concern about the MCMC performance.
\end{enumerate}

With the above points in mind, we have made the following modifications
to the manuscript to emphasise the key aspects of this example,
including:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  To the end of Section 1.1 ``\emph{It is in examples such as this one
  that we foresee the most use for chained Markov melding; a fully
  Bayesian approach is desired and the submodels are non-trivial in
  complexity, with no previously existing or obvious joint model.}''
\item
  To the end of the first paragraph of Section 3.: ``\emph{Avoiding
  concurrently evaluating all submodels also enables the reuse of
  existing software, minimising the need for custom submodel and/or
  sampler implementations.}''
\item
  To the end of the first paragraph of Section 5.1 ``\emph{Specifically,
  event times and indicators are a noninvertible function of other
  parameters in the first submodel, and are an uncertain response in the
  survival submodel. Chained Markov melding enables us to specify a
  suitable joint model despite these complications.}''
\item
  As the new third and forth sentences of paragraph 2 in Section 5.5
  ``\emph{Targeting} \(\pd_{1}(\phi_{1 \cap 2}, \psi_{1} \mid Y_{1})\)
  \emph{in stage one alleviates the need to solve Equation (46) within
  an MCMC iteration, instead turning the production of}
  \(\phi_{1 \cap 2}\) \emph{into an embarrassingly parallel,
  post-stage-one processing step. Attempting to sample the melded
  posterior directly would involve solving (46) many times within each
  iteration, presenting a sizeable computational hurdle which we
  avoid.}''
\end{enumerate}

\hypertarget{handling-editor}{%
\section*{Handling Editor}\label{handling-editor}}
\addcontentsline{toc}{section}{Handling Editor}

\begin{quote}
\(\hookrightarrow\)\textbf{HE}: \emph{On equation (42) what happens
when} \(x_{t - 1} = 0\)? \emph{Shouldn't the notation accommodate this
case?}
\end{quote}

Strictly yes, assuming the issue is that the \(\text{Poisson}(\lambda)\)
distribution is not typically defined when \(\lambda = 0\). We note that
this model is ubiquitous and this issue is ubiquitously ignored (Section
17.3 of \protect\hyperlink{ref-king_statistical_2011}{King, 2011}; the
``Materials and methods'' section in
\protect\hyperlink{ref-abadi_estimation_2010}{Abadi \emph{et al.},
2010}; Section 5.2.1 of
\protect\hyperlink{ref-finke_efficient_2019}{Finke \emph{et al.},
2019}). We have added the following sentence to the end of Section 4.2
reading

\begin{itemize}
\tightlist
\item
  ``\emph{If} \(x_{t - 1} = 0\) \emph{then we assume that the Poisson
  and binomial distributions become point masses at zero.}''
\end{itemize}

This assumption is ecologically reasonable -- if there are no owls alive
at time \(t - 1\), i.e.~\(x_{t - 1} = 0\), then the local population has
gone extinct and there will no more owls at times \(t, \ldots, T\). It
also aligns with the behaviour of \texttt{NIMBLE}/\texttt{rjags}, which
we use for this part of the example. Both will sample a node \texttt{x}
defined as \texttt{x\ \textasciitilde{}\ dpois(0.0)} with all samples
being \(0\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{suppressPackageStartupMessages}\NormalTok{(}\FunctionTok{library}\NormalTok{(nimble))}
\FunctionTok{suppressPackageStartupMessages}\NormalTok{(}\FunctionTok{library}\NormalTok{(dplyr))}
\FunctionTok{suppressPackageStartupMessages}\NormalTok{(}\FunctionTok{library}\NormalTok{(rjags))}

\NormalTok{samples\_nimble }\OtherTok{\textless{}{-}} \FunctionTok{nimbleCode}\NormalTok{(\{}
\NormalTok{  x }\SpecialCharTok{\textasciitilde{}} \FunctionTok{dpois}\NormalTok{(}\FloatTok{0.0}\NormalTok{)}
\NormalTok{\}) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{nimbleModel}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{nimbleMCMC}\NormalTok{(}\AttributeTok{niter =} \DecValTok{10}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{suppressMessages}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as.numeric}\NormalTok{()}

\NormalTok{samples\_nimble}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 0 0 0 0 0 0 0 0 0 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tf }\OtherTok{\textless{}{-}} \FunctionTok{tempfile}\NormalTok{()}
\NormalTok{mod }\OtherTok{\textless{}{-}} \StringTok{"model \{x \textasciitilde{} dpois(0.0)\}"} \SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{writeLines}\NormalTok{(}\AttributeTok{con =}\NormalTok{ tf)}

\NormalTok{samples\_jags }\OtherTok{\textless{}{-}} \FunctionTok{jags.model}\NormalTok{(tf, }\AttributeTok{quiet =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{jags.samples}\NormalTok{(}\AttributeTok{variable.names =} \StringTok{"x"}\NormalTok{, }\AttributeTok{n.iter =} \DecValTok{10}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  magrittr}\SpecialCharTok{::}\FunctionTok{extract2}\NormalTok{(}\StringTok{"x"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  magrittr}\SpecialCharTok{::}\FunctionTok{extract}\NormalTok{(, }\DecValTok{1} \SpecialCharTok{:} \DecValTok{10}\NormalTok{, )}

\NormalTok{samples\_jags}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 0 0 0 0 0 0 0 0 0 0
\end{verbatim}

\hypertarget{bibliography}{%
\section*{Bibliography}\label{bibliography}}
\addcontentsline{toc}{section}{Bibliography}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-abadi_estimation_2010}{}}%
Abadi, F., Gimenez, O., Ullrich, B., et al. (2010) Estimation of
immigration rate using integrated population models. \emph{Journal of
Applied Ecology}, \textbf{47}, 393--400. DOI:
\href{https://doi.org/10.1111/j.1365-2664.2010.01789.x}{10.1111/j.1365-2664.2010.01789.x}.

\leavevmode\vadjust pre{\hypertarget{ref-buchholz_adaptive_2021}{}}%
Buchholz, A., Chopin, N. and Jacob, P. E. (2021) Adaptive {Tuning} of
{Hamiltonian Monte Carlo Within Sequential Monte Carlo}. \emph{Bayesian
Analysis}, \textbf{16}. DOI:
\href{https://doi.org/10.1214/20-BA1222}{10.1214/20-BA1222}.

\leavevmode\vadjust pre{\hypertarget{ref-eddelbuettel_rcppsmc_2021}{}}%
Eddelbuettel, D., Johansen, A. M. and Zarubin, L. F. S. and I. (2021)
{RcppSMC}: {Rcpp} bindings for sequential {Monte Carlo}.

\leavevmode\vadjust pre{\hypertarget{ref-finke_efficient_2019}{}}%
Finke, A., King, R., Beskos, A., et al. (2019) Efficient sequential
{Monte Carlo} algorithms for integrated population models. \emph{Journal
of Agricultural, Biological and Environmental Statistics}, \textbf{24},
204--224. DOI:
\href{https://doi.org/10.1007/s13253-018-00349-9}{10.1007/s13253-018-00349-9}.

\leavevmode\vadjust pre{\hypertarget{ref-goudie_joining_2019}{}}%
Goudie, R. J. B., Presanis, A. M., Lunn, D., et al. (2019) Joining and
splitting models with {Markov} melding. \emph{Bayesian Analysis},
\textbf{14}, 81--109. {International Society for Bayesian Analysis}.
DOI: \href{https://doi.org/10.1214/18-BA1104}{10.1214/18-BA1104}.

\leavevmode\vadjust pre{\hypertarget{ref-johansen_smctc_2009}{}}%
Johansen, A. M. (2009) {SMCTC}: {Sequential Monte Carlo} in {C}++.
\emph{Journal of Statistical Software}, \textbf{30}, 1--41. DOI:
\href{https://doi.org/10.18637/jss.v030.i06}{10.18637/jss.v030.i06}.

\leavevmode\vadjust pre{\hypertarget{ref-king_statistical_2011}{}}%
King, R. (2011) Statistical ecology. In \emph{Handbook of {Markov Chain
Monte Carlo}} (eds S. Brooks, A. Gelman, G. Jones,et al.). Chapman
{\(\&\)} {Hall}/{CRC Handbooks} of {Modern Statistical Methods}. {CRC
Press}.

\leavevmode\vadjust pre{\hypertarget{ref-michaud_sequential_2020}{}}%
Michaud, N., de Valpine, P., Turek, D., et al. (2020) Sequential {Monte
Carlo} methods in the {NIMBLE R} package. \emph{arXiv:1703.06206
{[}stat{]}}. Available at: \url{https://arxiv.org/abs/1703.06206}.

\leavevmode\vadjust pre{\hypertarget{ref-nicholson_interoperability_2021}{}}%
Nicholson, G., Blangiardo, M., Briers, M., et al. (2021)
Interoperability of statistical models in pandemic preparedness:
Principles and reality. \emph{Statistical Science (forthcoming)}.
Available at: \url{https://arxiv.org/abs/2109.13730}.

\end{CSLReferences}

\newpage

\hypertarget{appendix}{%
\section*{Appendix}\label{appendix}}
\addcontentsline{toc}{section}{Appendix}

\begin{figure}
\includegraphics[width=24.6in]{plots/indiv-18-subset} \caption{Pairs plot for individual $i = 18$ in Example 2. The displayed are parameters are $\beta_{0, i}$ and $\xi_{i, 1}, \ldots, \xi_{i, 3}$.}\label{fig:coef_pairs}
\end{figure}

\end{document}
