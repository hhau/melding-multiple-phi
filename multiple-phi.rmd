---
title: "Chained Markov melding: multiple models with pairwise commonalities"
author: "Andrew Manderson"
date: "`r format(Sys.time(), '%d %B, %Y')`"
fontfamily: tgpagella
fontsize: 10pt
papersize: a4
geometry: margin=2.25cm
bibliography: bibliography/multi-phi-bib.bib
csl: bibliography/journal-of-the-royal-statistical-society.csl
link-citations: true
hyperrefoptions:
  - backref
  - colorlinks=true
output: 
  pdf_document:
    includes:
      in_header:
        tex-input/pre.tex
    fig_caption: true
    number_sections: true
    keep_tex: true
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, comment = NA, out.width = "99%", fig.align = "center", auto_pdf = TRUE)
```
\begin{abstract}
    - Something about multiple sources of information / data / models
    - markov melding and it's extensions 
    - why this work is distinct and why it's interesting
    - A bit about the examples
    - it's contribution in a sentence
\end{abstract}

# Introduction

The Bayesian philosophy is appealing in part because the posterior distribution quantifies all sources of uncertainty. 
However, a joint model for all data and parameters is a prerequisite to posterior inference, and in situations where multiple, heterogeneous sources of data are available, specifying such a joint model is challenging. 
Models that consider such data are necessary to describe complex phenomena at a useful precision.
One possible approach begins by specifying individual submodels for each source of data.
These submodels could informally guide the statistician when directly specifying the joint model, but to use the submodels only informally seems wasteful.
Instead, it may be preferable to construct a joint model by formally joining the individual submodels together. 

Composing disparate data and/or submodels to from the joint model is a well established idea and central to many methodologies.
Meta-analyses and evidence synthesis methods are important modelling techniques that summarise many disparate data, often using hierarchical models [@ades_multiparameter_2006; @presanis_synthesising_2014].
Outside of the statistical literature, a common name for combining multiple data is _data fusion_ [@lahat_multimodal_2015-1; @kedem_statistical_2017], though there are many distinct methods that fall under this general name.
More familiar to Bayesian statisticians are the family of _divide and conquer_ methods (D&C).
These are useful in tall data settings, where the number of observations presents a computational challenge.
D&C methods split the data into subsets, fit the same model to each subset to produce the subposteriors, and combine these subposteriors.
Specific D&C methods include _consensus Monte Carlo_ [@scott_bayes_2016-1],
the embarrassingly parallel MCMC algorithm of @neiswanger_asymptotically_2014, and subposterior averaging via the Wasserstein baryceter [@srivastava_scalable_2018].
The _Bayesian Fusion_ method of @dai_monte_2019-1 combines these subposteriors exactly.

Sometimes we may wish to think of a joint model in distinct submodels or 'modules'.
This is particularly important when one submodel is misspecified [@liu_modularization_2009; @jacob_better_2017-1] and we want to limit the flow of information out of the misspecified module [@lunn_bugs_2009; @plummer_cuts_2015].
The resulting posterior distribution is called the _cut_ distribution. 
_Semi-modular_ inference extends inter-module cuts to include all possible models in-between the standard Bayesian model and the cut model [@carmona_semi-modular_2020].
Whilst the motivation is not to overcome difficulties in specifying the joint model, these are interesting examples of 'modular thinking'.

Applied researchers often collect multiple disparate data sets, or data of different modalities, and wish to combine them. 
For example, @donnat_bayesian_2020 build an intricate hierarchical model to estimate true COVID-19 diagnosis that integrates both testing data and self-reported questionnaire data, and @parsons_evaluating_2020 specify a hierarchical model of similar complexity to estimate the number of injecting drug users in Ukraine. 
Both applications clearly delineate between the numerous sources of data they consider.
In conservation ecology, _integrated population models_ (IPMs) [@zipkin_synthesizing_2018] are used to estimate population level quantities, e.g. reproduction and immigration rates, using multiple data on the same population.
Such data have standard models associated with them, for example the Cormack—Jolly—Seber model [@lebreton_modeling_1992] is standard for capture-recapture data, and the IPM serves as the framework in which the standard models are combined.

_Markov melding_ [@goudie_joining_2019] is a general statistical methodology for combining submodels.
Specifically, it considers $M$ submodels that share some common quantity $\phi$.
Each of the $\modelindex = 1, \ldots, M$ submodels also has distinct parameters $\psi_{\modelindex}$, data $Y_{\modelindex}$ and form $\pd_{\modelindex}(\phi, \psi_{\modelindex}, Y_{\modelindex})$. 
The assumption that all submodels contain the same $\phi$ is common to many of the aforementioned modular inference methods.
However, we will later consider examples where the submodels do not relate in this way.
Our examples consist of the simplest possible, yet useful IPM that does not satisfy the common $\phi$ assumption; and a survival analysis where the event times are unobserved, uncertain quantities.
Specifically we consider the 3 submodel case, where submodel 1 and 2 share a common quantity $\phi_{1 \cap 2}$, and submodel 2 and 3 share a common quantity $\phi_{2 \cap 3}$.
We extend Markov melding to enable the combination of submodels that share quantities in such a pairwise manner, and we call our extension _chained Markov melding_, as the submodels are 'chained' together.

The computational effort required to fit a complex, multi-response model is a burden to the model development process.
Our chained melded model has a number of desirable computational properties that can reduce this burden. 
By considering the submodel as the minimum computational unit, we may be able to parallelise aspects of the computation, and use less expensive computational techniques for some submodels.
Reusing previous software implementations of submodels, and where available subposterior samples, may also be possible.
We propose a multi-stage posterior estimation method that samples the subposterior of $\pd_{1}$ and $\pd_{3}$ in parallel, and the samples are then reused in later stages.
Multi-stage samplers are used in many applied settings, including hierarchical modelling [@lunn_fully_2013-1] and joint models [@mauff_joint_2020], and can aid in understanding the contribution of each submodel to the final posterior.

## Example introduction

Our motivation arises from applications that can be recast, and perhaps more easily understood, as components of our chained melded model.
We introduce these models now to familiarise the reader with types of data and a subset of the domains in which modular inference methods are useful.

### An Integrated population model for little owls

<!-- do we want to frame this as a joining or a splitting example? -->

Integrated population models (IPMs) [@zipkin_synthesizing_2018] allow for precise estimation of population level quantities.
@schaub_local_2006 and @abadi_estimation_2010 used an IPM to estimate fecundity, immigration, and yearly survival rates for a population of little owls.
These authors collect and model three types of data, illustrated in Figure \ref{fig:owls-simple-dag}: capture-recapture data $Y_{1}$ with associated capture-recapture submodel $\pd_{1}(\phi_{1 \cap 2}, \psi_{1}, Y_{1})$; population counts $Y_{2}$ with associated submodel $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3}, \psi_{2}, Y_{2})$; and nest-record data $Y_{3}$ with associated fecundity submodel $\pd_{3}(\phi_{2 \cap 3}, \psi_{3}, Y_{3})$.
The population count model $\pd_{2}$ shares the parameter $\phi_{1 \cap 2}$ with the capture-recapture model $\pd_{1}$, and the parameter $\phi_{2 \cap 3}$ with the fecundity model $\pd_{3}$.
This model combination step is important as no single source of data is sufficient to estimate all quantities of interest to the desired precision.
We will show that the chained Markov melding framework developed in Section \ref{model-specification} shows how to integrate these submodels, and IPMs in general.

\input{tex-input/owls-example/0001-owls-simple-dag.tex}

### Survival analysis with time varying covariates and uncertain event times

Joint models for longitudinal and survival data [@rizopoulos_joint_2012] are popular models when longitudinal, often biomarker, data are available concurrently with time to event data.
Complicated longitudinal processes require flexible regression models, often including many subject specific parameters, and can be computationally challenging to fit jointly with time to event data.
This motivates a two-stage approach, where the longitudinal submodel is fit first and the fitted values are then used in the survival submodel [@tsiatis_joint_2004; @mauff_joint_2020].

In some settings the time at which the relevant event occurs is inherently uncertain.
This can be due to the definition of the event, for example the time when a measurable but noisy quantity crosses a prescribed threshold, or because the event of interest is inherently unobservable and must be inferred from other information.
_First hitting time_, or _threshold regression_ models [@lee_threshold_2006] are used in threshold crossing settings, and applications include kidney failure [@diggle_real-time_2015], dementia diagnosis [@hashemi_latent_2003], and disease transmission [@yu_semi-parametric_2009].
These methods assume that relevant measurements are realisations from a specific, possibly latent, stochastic process, where the distribution of the threshold crossing time is known.
A conceptually similar idea is presented in @lu_using_1993 and @sweeting_estimating_2010; both use hierarchical regression models instead of stochastic processes, and define the event time as when the estimated regression curve crosses the threshold.  
Another setting in which inherently uncertain event times arise is record linkage [@harron_methodological_2015].
Such settings are unique in that the true event time is assumed to be one of a finite set of possible times, with one possible event time arising from each matching record.
Integrating this uncertainty into standard survival models is challenging but possible [@wang_integrative_2020], however these methods do not consider event times that are continuous[^wang].

[^wang]: @wang_integrative_2020 assume that the response is a finite mixture, where each mixture component is a point mass at the possible event times arising due to record linkage. Uncertainty is then incorporated by estimating the mixture weights.

It seems desirable to integrate both uncertain event times and longitudinal data in a survival analysis.
Doing so in a standard joint model is challenging, as incorporating uncertainty in the response requires complex methodology [@giganti_accounting_2020; @oh_considerations_2018; @oh_raking_2021] which do not explicitly include time-varying covariates.
Similarly, incorporating time-varying covariates into a threshold regression model is nontrivial, and assumes the relevant covariates satisfy the Markov property [@lee_threshold_2010].
 <!-- - Another is that integrating time dependent covariates into the FHT/TR models is non straightforward -- as far as I can tell the Markov assumption in Lee and Whitmore is equivalent to restricting the form of the longitudinal submodel to linear forms (non linear longitudinal regression models are non-Markovian / joint model that depend on the integral of the longitudinal model are definitely non-Markovian. This is discussed a bit in @lee_threshold_2010)
    - it would help if our longitudinal model was non-linear so that we could have this benefit -- maybe making the regression quadratic.
  - One motivation comes from the respiratory failure idea and its similarities to the degradation models. (what would the other, longitudinal covariate be?)
    - This would be strengthened by using non-linear regression / splines for the first submodel. -->
Modular inference methods, and chained Markov melding in particular, offer conceptually straightforward approaches.
Specifically, we consider the event time as an uncertain, latent submodel quantity in a simplified, hierarchical degradation model akin to @lu_using_1993. 
We call this submodel the _uncertain event time_ submodel and denote it $\pd_{1}(\phi_{1 \cap 2}, \psi_{1}, Y_{1})$, and where $\phi_{1 \cap 2}$ is the latent event time.
The survival submodel $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3}, \psi_{2}, Y_{2})$ uses $\phi_{1 \cap 2}$, the common quantity, as the response. 
We treat the longitudinal submodel, $\pd_{3}(\phi_{2 \cap 3}, \psi_{3}, Y_{3})$, separately from the survival submodel, as is common in two-stage survival modelling, and denote the subject-specific parameters that also appear in the survival model as $\phi_{2 \cap 3}$.
The high level submodel relationships are displayed as a DAG in Figure \ref{fig:surv-simple-dag}.

\input{tex-input/surv-example/0001-surv-simple-dag.tex}

# Model specification

Our intention is to combine submodels into a specific joint model which we call the _chained melded model_[^chained].
Consider $\modelindex = 1, \ldots, \Nm$ submodels each with distinct data $Y_{\modelindex}$ and parameters $\psi_{\modelindex}$.
Additionally, each submodel shares some quantity in common with adjacent submodels $\phi_{\modelindex \cap \modelindex'}$, where $\modelindex \neq \modelindex'$.

We focus in the main text on the $\Nm = 3$ submodel special case, where submodels $\pd_{1}(\phi_{1 \cap 2}, \psi_{1}, Y_{1})$ and $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3}, \psi_{2}, Y_{2})$ have $\phi_{1 \cap 2}$ in common, and $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3}, \psi_{2}, Y_{2})$ and $\pd_{3}(\phi_{2 \cap 3}, \psi_{3}, Y_{3})$ both contain $\phi_{2 \cap 3}$;
the appendix contains the general $\Nm$-model case.
Each submodel is assumed to be a valid joint density function for all constituent quantities, and all submodel conditionals exist with appropriate support.

[^chained]: _"Chained graphs"_ were considered by @lauritzen_chain_2002, however they are unrelated to our proposed model. We use "chained" to emphasise the nature of the relationships between submodels.

## Chained melded model

We begin by defining the chained melded model in terms of submodel conditional distributions
\input{tex-input/multiple-phi/0010-melded-model-cond.tex}
where the specification of each submodel is conditional on the quantities it has in common with adjacent submodels, and we impose a joint prior for $(\phi_{1 \cap 2}, \phi_{2 \cap 3})$ which we will return to momentarily.
However, these conditional distributions of are not always analytically tractable.
Each conditional distribution can be written in terms of the submodel joint density and appropriate marginal, and we rewrite the right hand side of Equation \eqref{eqn:melded-model-cond} as
\input{tex-input/multiple-phi/0012-melded-model-full.tex}
We refer to Equation \eqref{eqn:melded-model-full} as the melded model, and note that it is proportional to the melded posterior $\pd_{\text{meld}}(\phi_{1 \cap 2}, \phi_{2 \cap 3}, \psi_{1}, \psi_{2}, \psi_{3} \mid Y_{1}, Y_{2}, Y_{3})$.

## Pooled prior

Specifying \eqref{eqn:melded-model-full} requires forming an appropriate joint prior for $(\phi_{1 \cap 2}, \phi_{2 \cap 3})$.
Markov melding proceeds by pooling [@ohagan_uncertain_2006] the submodel priors to form such a prior, denoted $\pd_{\text{pool}}$.
We will do the same, however we have the additional complication that $\phi_{1 \cap 2}$ and $\phi_{2 \cap 3}$ may have different supports.
Consequently, we extend linear and logarithmic pooling to handle marginals with different supports, to produce a valid density for $\pd_{\text{pool}}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$.

Throughout we assume that $\pd_{1}(\phi_{1 \cap 2}), \pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$, and $\pd_{2}(\phi_{2 \cap 3})$ are normalised, integrable probability density functions, that $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$ admits proper marginals for $\pd_{2}(\phi_{1 \cap 2})$ and $\pd_{2}(\phi_{2 \cap 3})$, and proper conditionals for $\pd_{2}(\phi_{1 \cap 2} \mid \phi_{2 \cap 3})$ and $\pd_{2}(\phi_{2 \cap 3} \mid \phi_{1 \cap 2})$.
For simplicity we will also assume that $\phi_{1 \cap 2} \in \mathbb{R}^{d_{1}}$ and $\phi_{2 \cap 3} \in \mathbb{R}^{d_{2}}$, and the supports of $\pd_{1}(\phi_{1 \cap 2}), \pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$, and $\pd_{2}(\phi_{2 \cap 3})$ are $\mathbb{R}^{d_{1}}, \mathbb{R}^{d_{1}} \times \mathbb{R}^{d_{2}}$, and $\mathbb{R}^{d_{2}}$ respectively.

#### Linear pooling

We propose the following two-step linear pooling approach.
The first step forms intermediary pooling densities via standard linear pooling, using appropriate marginals with common support
\input{tex-input/multiple-phi/0054-silly-linear-solution.tex}
In step two we form the pooled prior as the product of the intermediaries
\input{tex-input/multiple-phi/0055-silly-linear-overall.tex}
Equation \eqref{eqn:silly-linear-overall} implies that our linear pooling process will always produce a pooled prior with no correlation between $\phi_{1 \cap 2}$ and $\phi_{2 \cap 3}$, which may be undesirable.
It is possible to induce correlation between independent marginal distributions via copulas [@nelsen_introduction_2006] and other techniques [@lin_recent_2014], but these methods are less intuitive than capturing dependence in the pooling process.

#### Logarithmic pooling.

A multiplicative alternative to linear pooling is logarithmic pooling.
We define the logarithmically pooled prior to be 
\input{tex-input/multiple-phi/0050-pooled-prior-overall.tex}
This is a valid probability density function for $\pd_{\text{pool}}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$, due to our assumption that all prior marginal distributions are proper. 
Unlike linear pooling, correlation present in $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$ will persist in $\pd_{\text{pool}}$.
Product-of-experts pooling is a special case of logarithmic pooling that occurs when $\lambda_{\modelindex} = 1, \, \forall \modelindex$.


### Pooling weights

Choosing values for the pooling weights ($\lambda$) is an important step in specifying $\pd_{\text{pool}}$.
To understand how $\lambda$ and the choice of pooling method impacts $\pd_{\text{pool}}$, we pool some simple marginal distributions and visualise the result. 
We recommend producing such prior predictive visualisations as part of a Bayesian workflow [@gelman_bayesian_2020], to ensure the pooled prior is fit for purpose.

Specifically, we pool the following marginal normal distributions
\input{tex-input/multiple-phi/0061-marginal-gaussian-example.tex}
where $\text{N}(\phi; \mu, \sigma^{2})$ is the normal density function with mean $\mu$ and standard deviation $\sigma$.
The two dimensional density function $\pd_{2}$ has an additional parameter $\rho$, which controls the intra-submodel marginal correlation.
We set $\mu_{1} = -2.5, \mu_{2} = \left[\mu_{2, 1} \,\, \mu_{2, 2}\right]' = \left[0 \,\, 0\right]', \mu_{3} = 2.5, \sigma_{1}^{2} = \sigma_{2}^{2} = \sigma_{3}^{2} = 1$ and $\rho = 0.8$.
In the logarithmic case we set $\lambda_{1} = \lambda_{3}$ and parameterise $\lambda_{2} = 1 - 2\lambda_{1}$, so that $\lambda_{1} + \lambda_{2} + \lambda_{3} = 1$ whilst limiting ourselves to varying only $\lambda_{1}$.
Similarly, in the linear case we set $\lambda_{1, 1} = \lambda_{2, 2} = \lambda_{1}$ and $\lambda_{1, 2} = \lambda_{2, 1} = 1 - 2 \lambda_{1}$.
We consider 5 evenly spaced values of $\lambda_{1} \in [0, 0.5]$.
For both pooling methods, as $\lambda_{1}$ increases, the contributions of $\pd_{1}(\phi_{1 \cap 2})$ and $\pd_{3}(\phi_{2 \cap 3})$ increase. 
As expected, using linear pooling produces a $\pd_{\text{pool}}$ with no correlation, due to the additive form of Equations \eqref{eqn:silly-linear-solution-1} and \eqref{eqn:silly-linear-solution-2}.
A large, near-flat plateau is visible in the $\lambda_{1} = 0.25$ case, which is a result of the mixture of four, 2-D normal distributions that linear pooling produces in this example.
The logarithmic pooling process produces a more concentrated prior for small values of $\lambda_{1}$.
Correlation is preserved for all $\lambda_{1} \neq 0.5$, and Appendix \ref{log-pooling-gaussian-densities} analytically shows that $\lambda_{2}$ controls the quantity of correlation present in $\pd_{\text{pool}}$ in this setting./

```{r pooled_densities_plot, fig.cap = "Contour plots of $\\pd_{\\text{pool}}$ (red) under logarithmic and linear pooling (left and right column respectively). The values of $\\lambda_{1}$ are indicated in the plot titles, and the constituent marginal densities are shown in blue."}
knitr::include_graphics("plots/pooling-tests/version-two.pdf")
```

# Coherency of the chained melded model

- _I think a few of these results are wrong. Maybe this should just be a paragraph?_
    - 3 ii) is definitely wrong.
    - 3 i) doesn't required independence 
- _Some discussion of the M = 3 case in text, with reference to the general case (if I can figure out what that even means) in the appendix_
- _I think I can also put together a discussion of what it means to be externally Bayesian in this context now?_.
    - _no_

A reasonable requirement for a modular inference method is that the final posterior distribution should not, at least theoretically, depend on the order in which data are observed or integrated into the model.
In the context of belief distributions, @bissiri_general_2016 call this property 'coherence', which we will co-opt.
Specifically, in the $\Nm = 3$ case, it seems desirable that the chained melded model be the same if either $\pd_{1}$ or $\pd_{3}$ are integrated with submodel $\pd_{2}$ first.
We will show that the form proposed in Equation \eqref{eqn:melded-model-full} satisfies this property, whilst the model produced by applying the melding method of @goudie_joining_2019 is, in general, sensitive to the order of integration.
    <!-- 
        - should we also check p(13)2?
            - (13)2 is the same as original melding with \phi = (\phi_{1 \cap 2}, \phi_{2 \cap 3}),
            - but the strategy doesn't generalise to higher $M$ (M = 4 immediately disproves)

        - say we had 9 models, and the first three formed \pd_{1}, the second three formed \pd_{2} and the remaining $\pd_{3}$. Would we apply melding here twice? No, we would think about this as chained melding with M = 9 models.
    -->

## Applying Markov melding twice

The general thing I want to be able to say is


The idea is that they can only possibly be equal if there is prior independence between the common quantities in each submodel.
If this is missing, then for any, non product-of-experts, choice of weight functions

Denote the original melding operator with $\circledast$. 
Its output is 
\input{tex-input/noncommutativity/0005-def-usual-melded-model.tex}
where $\pd_{\text{pool}}^{12}(\phi_{1 \cap 2}) = g^{12}(\pd_{1}(\phi_{1 \cap 2}), \pd_{2}(\phi_{1 \cap 2}))$ for some pooling function $g^{12}$.
We denote the parameter space of the output as $\boldsymbol{\Theta}_{12} = (\phi_{1 \cap 2}, \phi_{2 \cap 3}, \psi_{1}, \psi_{2}, Y_{1}, Y_{2})$, so that any prior marginal distribution of $\pd_{\text{meld}}^{12}$ can be derived by integrating out the irrelevant components of $\boldsymbol{\Theta}_{12}$.
For example,  
\input{tex-input/noncommutativity/0006-example-melded-marginal-definition.tex}
where $\boldsymbol{\Theta}_{12} \setminus \phi_{2 \cap 3}$ is $\boldsymbol{\Theta}_{12}$ without $\phi_{2 \cap 3}$.

To integrate third submodel, we apply the original operator to $\pd_{\text{meld}}^{12}$ and $\pd_{3}$
\input{tex-input/noncommutativity/0007-iterated-application-melding.tex}
so that the parentheses in the superscript of $\pd_{\text{meld}}^{(12)3}$ indicate the order in which the submodels are melded.
As before we define $\pd_{\text{pool}}^{(12)3}(\phi_{2 \cap 3}) = g^{(12)3}(\pd_{\text{meld}}^{12}(\phi_{2 \cap 3}), \pd_{3}(\phi_{2 \cap 3}))$, but for a potentially different choice of pooling function $g^{(12)3}$.

It will be convenient to consider the following, expanded form of Equation \eqref{eqn:iterated-application-melding-two}
\input{tex-input/noncommutativity/0013-expanded-double-melded-model.tex}
and the equivalent expression for $\pd_{\text{meld}}^{1(23)}$, which we derive by careful inspection of the superscripts
\input{tex-input/noncommutativity/0018-symmetric-expanded-double-melded-model.tex}

## Does melding twice produce the same model as the chained melded model?

For Equations \eqref{eqn:expanded-double-melded-model} and \eqref{eqn:symmetric-expanded-double-melded-model} to be equal to the model defined in Equation \eqref{eqn:melded-model-full}, the following equalities must hold:
\input{tex-input/noncommutativity/0040-coinciding-equalities.tex}
It is clear from Equation \eqref{eqn:coinciding-equalities-one} that one necessary condition is for $\phi_{1 \cap 2}$ and $\phi_{2 \cap 3}$ to be _a priori_ independent in $\pd_{2}$.

### Melded marginal equality

By inspecting Equation \eqref{eqn:coinciding-equalities-one} we note the additional necessary condition that $\pd_{\text{meld}}^{12}(\phi_{2 \cap 3}) = \pd_{2}(\phi_{2 \cap 3})$.
To see when this is true, consider the following derivation
\input{tex-input/noncommutativity/0015-verify-dictatorial-pooling.tex}
Hence, for $\pd_{\text{meld}}^{12}(\phi_{2 \cap 3}) = \pd_{2}(\phi_{2 \cap 3})$ to hold we require $\pd_{\text{pool}}^{12}(\phi_{1 \cap 2}) = \pd_{2}(\phi_{1 \cap 2})$.
This is _dictatorial pooling_, where one submodel's prior marginal is used as a prior in the melded model.
An identical argument can be used to show that $\pd_{\text{meld}}^{23}(\phi_{1 \cap 2}) = \pd_{2}(\phi_{1 \cap 2})$ requires the equivalent choice of dictatorial pooling for $\phi_{2 \cap 3}$, i.e. $\pd_{\text{pool}}^{23}(\phi_{2 \cap 3}) = \pd_{2}(\phi_{2 \cap 3})$.

### Pooling equality

Without any loss of generality, we examine only the $\pd_{\text{pool}}^{12}(\phi_{1 \cap 2}) \pd_{\text{pool}}^{(12)3}(\phi_{2 \cap 3}) = \pd_{\text{pool}}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$ equality in Equation \eqref{eqn:coinciding-equalities-two} for further necessary conditions.
There are three decisions to be made about the method of pooling used on the right hand side (RHS) of this equality:

1. Form $\pd_{\text{pool}}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$ via the logarithmic pooling method of Equation \eqref{eqn:pooled-prior-overall}.
    
    Logarithmic pooling results in a RHS proportional to $\pd_{1}(\phi_{1 \cap 2})^{\lambda_{1}} \pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})^{\lambda_{2}} \pd_{3}(\phi_{2 \cap 3})^{\lambda_{3}}$.
    Hence both $g^{12}$ and $g^{(12)3}$ are logarithmic pooling functions; if either were a linear pooling function we would get more than one term, and if either were dictatorial the left hand side (LHS) would exclude either $\pd_{1}(\phi_{1 \cap 2})$ or $\pd_{3}(\phi_{2 \cap 3})$.
    Thus,
    \input{tex-input/noncommutativity/0041-pooling-equality-rhs-log.tex}
    for arbitrary positives weights $\lambda_{\cdot}$.
    Equation \eqref{eqn:pooling-equality-rhs-log} holds iff $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3}) = \pd_{2}(\phi_{1 \cap 2})\pd_{2}(\phi_{2 \cap 3})$ and $\pd_{\text{meld}}^{12}(\phi_{2 \cap 3}) = \pd_{2}(\phi_{2 \cap 3})$. 
    We have shown earlier that is only true if dictatorial pooling is used for $g^{12}$.
    But if $g^{12}$ is dictatorial, then the LHS of Equation \eqref{eqn:pooling-equality-rhs-log} would not contain a $\pd_{1}(\phi_{1 \cap 2})$ term, which is a contradiction.
    Hence, Equation \eqref{eqn:pooling-equality-rhs-log} is not true in general.

    A special case of logarithmic pooling is that of product of experts, where $g^{12}(\pd_{1}(\phi_{1 \cap 2}), \pd_{2}(\phi_{1 \cap 2})) = \pd_{1}(\phi_{1 \cap 2})\pd_{2}(\phi_{1 \cap 2})$ and $g^{(12)3}(\pd_{\text{meld}}^{12}(\phi_{2 \cap 3}), \pd_{3}(\phi_{2 \cap 3})) = \pd_{\text{meld}}^{12}(\phi_{2 \cap 3})\pd_{3}(\phi_{2 \cap 3})$.
    In this specific instance all prior terms cancel, and only terms containing data remain in the melded model, so Equation \eqref{eqn:pooling-equality-rhs-log} is trivially true (both sides are equal to 1).

2. From $\pd_{\text{pool}}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$ via the linear pooling method of Equations \eqref{eqn:silly-linear-solution-1} -- \eqref{eqn:silly-linear-overall}.

    If linear pooling is used then the RHS contains 4 terms.
    Thus both $g^{12}$ and $g^{1(23)}$ are linear -- all other combinations of pooling functions produce fewer than four terms -- and results in
    \input{tex-input/noncommutativity/0042-pooling-equality-rhs-lin.tex}
    Equation \eqref{eqn:pooling-equality-rhs-lin} again requires $\pd_{\text{meld}}^{12}(\phi_{2 \cap 3}) = \pd_{2}(\phi_{2 \cap 3})$, which we have shown to only be possible under dictatorial pooling.
    Thus we arrive at the same contradiction as before.

3. Use dictatorial pooling.
    
    There are two valid dictatorial pooling choices for the RHS:

    i. Set $\pd_{\text{pool}}(\phi_{1 \cap 2}, \phi_{2 \cap 3}) = \pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$.

        If one chooses $g^{12}(\pd_{1}(\phi_{1 \cap 2}), \pd_{2}(\phi_{1 \cap 2})) = \pd_{2}(\phi_{1 \cap 2})$ and $g^{(12)3}(\pd_{\text{meld}}^{12}(\phi_{2 \cap 3}), \pd_{3}(\phi_{2 \cap 3})) = \pd_{\text{meld}}^{12}(\phi_{2 \cap 3})$, then Equation \eqref{eqn:coinciding-equalities-two} simplifies to $\pd_{2}(\phi_{1 \cap 2}) \pd_{\text{meld}}^{12}(\phi_{2 \cap 3}) = \pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$, which is true iff the prior independence assumption is satisfied.
        Additionally, we require $\pd_{\text{meld}}^{12}(\phi_{2 \cap 3}) = \pd_{2}(\phi_{2 \cap 3})$, which as we have noted, is only true if $g^{12}$ is dictatorial.
        In this case, unlike previous cases, $g^{12}$ is exactly the dictatorial pooling function we require.

    i. Set $\pd_{\text{pool}}(\phi_{1 \cap 2}, \phi_{2 \cap 3}) = \pd_{1}(\phi_{1 \cap 2}) \pd_{3}(\phi_{2 \cap 3})$.

        Satisfying Equation \eqref{eqn:coinciding-equalities-two} is possible in this case if $g^{12}(\pd_{1}(\phi_{1 \cap 2}), \pd_{2}(\phi_{1 \cap 2})) = \pd_{1}(\phi_{1 \cap 2})$ and $g^{(12)3}(\pd_{\text{meld}}^{12}(\phi_{2 \cap 3}), \pd_{3}(\phi_{2 \cap 3})) = \pd_{3}(\phi_{2 \cap 3})$.

So in general, applying the original melding operator twice does not result in the same model as \eqref{eqn:melded-model-full}, except in cases where $\phi_{1 \cap 2}$ and $\phi_{2 \cap 3}$ are a priori independent in $\pd_{2}$ and specific forms of dictatorial pooling are used.

## Is the original operator commutative? 

Commutativity of the original operator would imply that $(\pd_{1} \circledast \pd_{2}) \circledast \pd_{3} = \pd_{1} \circledast (\pd_{2} \circledast \pd_{3})$.
By carefully considering the indices in Equation \eqref{eqn:expanded-double-melded-model} and \eqref{eqn:symmetric-expanded-double-melded-model}, we find that the original melding operator is only commutative if 
\input{tex-input/noncommutativity/0016-commutativity-condition.tex}
which implies the following equalities
\input{tex-input/noncommutativity/0014-orig-melding-commutative-equalities.tex}
Showing one of the equalities in Equation \eqref{eqn:orig-melding-commutative-equalities-1} and \eqref{eqn:orig-melding-commutative-equalities-2} implies its partner equality is also true. 
Consider the first equality
\input{tex-input/noncommutativity/0017-pooling-equality.tex}
Assume that $g^{12}$ and $g^{1(23)}$ are both linear or logarithmic pooling functions.
For Equation \eqref{eqn:pooling-equality} to be true, $\pd_{2}(\phi_{1 \cap 2}) = \pd_{\text{meld}}^{23}(\phi_{1 \cap 2})$, which is the same result we require in Equation \eqref{eqn:orig-melding-commutative-equalities-2}.
We have already shown that this is only true when using certain forms of dictatorial pooling.
Hence, the original operator is commutative under in the same settings in which applying the original melding operator twice results in the chained melded model.
 
# Posterior estimation

We now present two multi-stage MCMC methods for generating samples from the melded posterior.
By employing a multi-stage strategy we can avoid evaluating all submodels simultaneously.
This is desirable in situations where simultaneously evaluating the submodel terms is computationally infeasible or otherwise undesirable, whilst evaluating the prior marginal distributions is possible and relatively inexpensive.
The first sampler operates sequentially, accruing and refining samples by considering one submodel at a time.
The second parallelises parts of the sampling process, and has the potential to produce a sample, usable for inference, from the melded posterior in less time than the sequential method.

We also describe an approximate method, where stage one submodels are summarised by normal distributions for use in stage two.

## Sequential sampler

Stage one ($s_{1}$) of the sequential sampler targets terms from submodel $\pd_{1}$. 
The target is expanded in stage two ($s_{2}$) to also include $\pd_{2}$ terms, finally to include $\pd_{3}$ terms and $\pd_\text{pool}$ in stage three ($s_{3}$).
An overview of this target broadening process is displayed in Figure \ref{fig:seq-sampler-dag}
\input{tex-input/multi-stage-sampler/0001-seq-sampler-dag.tex}
    
#### Stage one

Mathematically, stage one of the sequential sampler targets
\input{tex-input/multi-stage-sampler/0020-stage-one-target.tex}
using a generic proposal kernel for both $\phi_{1 \cap 2}$ and $\psi_{1}$. 
The corresponding acceptance probability for a proposed update from $(\phi_{1 \cap 2}, \psi_{1})$ to $(\phi_{1 \cap 2}^{*}, \psi_{1}^{*})$ is
\input{tex-input/multi-stage-sampler/0021-stage-one-acceptance-probability.tex}

#### Stage two

The stage two target augments the stage one target by including the second submodel and corresponding prior marginal distribution,
\input{tex-input/multi-stage-sampler/0030-stage-two-target.tex}
A Metropolis-within-Gibbs strategy is employed, where the stage one samples are used as a proposal for $\phi_{1 \cap 2}$, whilst a generic proposal kernel is used for $\psi_{2}$ and $\phi_{2 \cap 3}$.
Thus the proposal distributions for $\phi_{1 \cap 2}^{*}$ and $(\phi_{2 \cap 3}^{*}, \psi_{2}^{*})$ are 
\input{tex-input/multi-stage-sampler/0031-stage-two-gibbs-updates.tex}
The acceptance probability for this proposal strategy is
\input{tex-input/multi-stage-sampler/0032-stage-two-acceptance-probabilities.tex}
Our judicious choice of proposal distribution has resulted in a cancellation in Equation \eqref{eqn:stage-two-acceptance-probabilities-one} which removes all terms related to $\pd_{1}$.
Similarly, all terms related to $\pd_{1}$ are constant -- hence cancel -- in Equation \eqref{eqn:stage-two-acceptance-probabilities-two}.
This eliminates any need to re-evaluate the first submodel.

#### Stage three

In stage three we target the full melded posterior
\input{tex-input/multi-stage-sampler/0044-stage-three-target.tex}
The target has now been broadened to include terms from the third submodel and the pooled prior.
Again, we employ a Metropolis-within-Gibbs sampler, with proposals drawn such that
\input{tex-input/multi-stage-sampler/0045-stage-three-gibbs-updates.tex} 
which leads to acceptance probabilities of
\input{tex-input/multi-stage-sampler/0046-stage-three-acceptance-probabilities.tex}
The informed choice of proposal distribution for ($\phi_{1 \cap 2}, \phi_{2 \cap 3}, \psi_{1}, \psi_{2}$) has allowed us to target the full melded posterior without needing to evaluate all submodels simultaneously.  

## Parallel sampler

We now devise a strategy where stage one samples submodels 1 and 3 in parallel. Stage two reuses these samples in a Metropolis-within-Gibbs sampler, which targets the full melded posterior.
The stage specific targets are displayed in Figure \ref{fig:parallel-dag}.

\input{tex-input/dc-sampler/0001-parallel-dag.tex}

#### Stage one

Two independent, parallel sampling processes occur in stage one.
Submodels one and three are targeted
\input{tex-input/dc-sampler/0021-stage-one-targets.tex}
using submodel-specific transition kernels, leading to acceptance probabilities of
\input{tex-input/dc-sampler/0022-stage-one-acceptance-probs.tex}
which can be computed independently of one another.

#### Stage two

Stage two targets the melded posterior of Equation \eqref{eqn:melded-model-full} using a Metropolis-within-Gibbs sampler, where the proposal distributions are
\input{tex-input/dc-sampler/0031-stage-two-proposals.tex}
The acceptance probabilities for these updates are
\input{tex-input/dc-sampler/0032-stage-two-acceptance.tex}
Note that all stage two acceptance probabilities only contain terms from the second submodel and the pooled prior.

## Normal approximations to submodel components

Normal approximations are commonly employed to summarise submodels for subsequent use in more complex models.
For example, two-stage meta-analyses often use a normal distribution centred on each studies' effect estimate [@burke_meta-analysis_2017].
Suppose we employ such an approximation to summarise the prior and posterior of $\phi_{1 \cap 2}$ and $\phi_{2 \cap 3}$ under $\pd_{1}$ and $\pd_{3}$ respectively.
In addition, assume that

- Such approximations are appropriate for $\pd_{1}(\phi_{1 \cap 2}), \pd_{1}(\phi_{1 \cap 2} \mid Y_{1}), \pd_{3}(\phi_{2 \cap 3})$, and $\pd_{3}(\phi_{2 \cap 3} \mid Y_{3})$.
- We are not interested in $\psi_{1}$ and $\psi_{3}$, and can integrate them out of all relevant densities.
- We employ dictatorial pooling and choose $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$ as the authoritative prior.

The latter two assumptions imply that the melded posterior of interest is proportional to
\input{tex-input/multiple-normal-approximation/0010-normal-approx-melded-posterior-target.tex}

In parallel, sample the prior and (sub)posterior of $\pd_{1}$ and $\pd_{3}$ and form normal approximations using these samples, e.g approximate $\pd_{1}(\phi_{1 \cap 2} \mid Y_{1})$ by a normal density with mean $\widehat{\mu}_{1}$ and covariance matrix $\widehat{\Sigma}_{1}$.
Denote the subposterior approximation $\widehat{\pd}_{1}(\phi_{1 \cap 2} \mid \widehat{\mu}_{1}, \widehat{\Sigma}_{1})$ and the prior approximation $\pd_{1}(\phi_{1 \cap 2}) \approx \widehat{\pd}_{1}(\phi_{1 \cap 2} \mid \widehat{\mu}_{1, 0}, \widehat{\Sigma}_{1, 0}) = \text{N}(\widehat{\mu}_{1, 0}, \widehat{\Sigma}_{1, 0})$, and corresponding approximations and parameters for $\pd_{3}$.
The approximate melded posterior is thus
\input{tex-input/multiple-normal-approximation/0020-normal-approximation-approximate-target.tex}
The product of independent normal densities is an unnormalised multivariate normal density with independent components, so we rewrite Equation \eqref{eqn:normal-approximation-approximate-target} as
\input{tex-input/multiple-normal-approximation/0030-normal-approx-nu-de-form.tex}
Finally, the ratio of normal densities is also an unnormalised normal density, and hence Equation \eqref{eqn:normal-approx-nu-de-form} simplifies to
\input{tex-input/multiple-normal-approximation/0040-final-normal-approx.tex}
Standard MCMC methods can be used to sample from the approximate melded posterior.
If instead we opt for product-of-experts pooling, all $\mu_{\text{de}}$ and $\Sigma_{\text{de}}$ terms disappear from the parameter definitions in Equation \eqref{eqn:final-normal-approx}.

# Examples

## Little owls

We now return to the integrated population model (IPM) for the little owls introduced in Section \ref{an-integrated-population-model-for-little-owls}.
Because the population count model includes a parameter also contained in the nest-record model, and has two parameters in common with the capture-recapture model, the IPM can be viewed as a chained melded model.
This IPM is one of the simplest cases of both an application requiring multiple sources of data to obtain sufficient precision, and chained Markov melding. 

### Submodels

@finke_efficient_2019 consider a number of variations on the original model of @schaub_local_2006 and @abadi_estimation_2010.
We consider variant from @finke_efficient_2019 with the highest marginal likelihood.
Before we detail the specifics of our chosen model, we need to introduce some notation. 
Data and parameters are stratified into two age-groups $a \in \{J, A\}$ where $J$ denotes juvenile owls and $A$ adults, Two sexes $s \in \{M, F\}$, and observations occur at times $t \in \{1, \ldots, T\}$, for $T = 25$.

#### Capture recapture: $\pd_{1}$

Capture-recapture data pertain to owls that are captured, tagged, and released at time $t$.
These individuals are then recaptured at time $u$, for $t + 1 < u < T + 1$, or not recaptured before the conclusion of the study, in which case $u = T + 1$. 
Define $M_{a, s, t, u}$ as the number of owls last observed at time $t$, recaptured at time $u$, of sex $s$, and age-group $a$.
These observations are then aggregated into age-group and sex specific matrices $\boldsymbol{M}_{a, s}$, with $T$ rows and $T + 1$ columns.
Let $R_{a, s, t} = \sum_{u = 1}^{T + 1} \boldsymbol{M}_{a, s, t, u}$ be the number of owls observed at time $t$ and then released, i.e. a vector containing the row-wise sum of the entries in $\boldsymbol{M}_{a, s}$.
The multinomial likelihood is
\input{tex-input/owls-example/0010-capture-recapture-submodel.tex}
with probabilities $\boldsymbol{Q}_{a, s, t} = \{Q_{a, s, t, u}\}_{u = 1}^{T + 1}$ such that
\input{tex-input/owls-example/0011-multinomial-probabilities.tex}

#### Count data model: $\pd_{2}$ 

To estimate population abundance, a two level model is used.
One level models the observed (counted) number of females at each point in time, with a second, latent process modelling the total number of females in population.
Denote the total number of juvenile and adult females in the population at time $t$ as $\boldsymbol{x}_{t} = \left[x_{J, t}, x_{A, t}\right]$.
The latent, population level model is 
\input{tex-input/owls-example/0020-count-data-submodel.tex}
Initial population sizes $(x_{J, 1}, x_{A, 1})$ are a priori uniformly distributed over $\{0, 1, \ldots, 50\}$.
The observation model is  
\input{tex-input/owls-example/0021-observation-process.tex}

#### Fecundity: $\pd_{3}$

The fecundity submodel considers the number of breeding females at time $t$, $N_{t}$, and the number of chicks produced that survive and leave the nest $n_{t}$.
A Poisson model is employed, with fecundity (reproductive) rate $\rho$
\input{tex-input/owls-example/0030-fecundity-submodel.tex}
 
#### Parameterisation and melding quantities

@abadi_estimation_2010 parameterise the time dependent quantities via linear predictors, to minimise the number of parameters in the submodels.
However, our choice to use the 'best' model of @finke_efficient_2019 renders many of the quantities independent of time.
The specific parameterisation we employ is
\input{tex-input/owls-example/0040-parameterisation-info.tex}
thus the quantities common to the submodels are $\phi_{1 \cap 2} = (\alpha_{0}, \alpha_{2})$ and $\phi_{2 \cap 3} = \rho$.
Our definition of $\phi_{1 \cap 2}$ does not include $\alpha_{1}$ as it is male specific and does not exist in $\pd_{2}$.
To align the notation of this example with the melding notation we define, for all permitted values of $a, s$ and $t$, $Y_{1} = \boldsymbol{M}_{a, s}$, $\psi_{1} = \pi_{s, t}$; $Y_{2} = y_{t}$, $\psi_{2} = (\boldsymbol{x}_{t}, \eta, \text{sur}_{t}, \text{imm}_{t})$; and $Y_{3} = (N_{t}, n_{t})$, $\psi_{3} = \varnothing$.
We use the priors of @abadi_estimation_2010 for the parameters in each submodel.
The components of $\alpha$ present in $\pd_{1}$ and $\pd_{2}$ are assigned independent $\text{N}(0, 100^2)$ priors which are truncated to $[-10, 10]$. 
A $\text{U}(0, 10)$ prior is assigned to $\rho$ in $\pd_{2}$ and $\pd_{3}$.

Completing the specification of $\pd_{\text{meld}}$ requires us to choose $\pd_\text{pool}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$.
So that we can appropriately compare the melded posterior with the IPM posterior $\pd_{\text{meld}}$ we opt for product-of-experts pooling: $\pd_\text{pool}(\phi_{1 \cap 2}, \phi_{2 \cap 3}) \propto \pd_{1}(\phi_{1 \cap 2}) \pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3}) \pd_{3}(\phi_{2 \cap 3})$.

- _Should I also run a variant that forms $\pd_{\text{pool}}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$ via one of our pooling methods?_

### Posterior estimation 

We estimate the melded posterior using both the normal approximation and parallel sampler described in Section \ref{parallel-sampler}.
This allows us to use pre-existing implementations of the submodels.
Specifically, the capture-recapture and count data submodels are written in BUGS [@lunn_bugs_2009], and the subposterior of the former is sampled via `rjags` [@plummer_rjags_2019]. 
The fecundity submodel is written in Stan [@carpenter_stan_2017] and sampled via `rstan` [@stan_development_team_rstan_2021].
We reuse the count data BUGS implementation for stage two of the multi-stage sampler, and implement the Metropolis-within-Gibbs sampler specified in Section \ref{parallel-sampler} via `Nimble` [@de_valpine_programming_2017] and its `R` interface [@nimble_development_team_nimble_2019].
A slightly modified version of the count data submodel used for the normal approximation, which is also run through `rjags`.
We highlight the use of different statistical software for each submodel, an advantage of this 'modular' approach to modelling.

Code and data for all examples are available at [https://github.com/hhau/melding-multiple-phi](https://github.com/hhau/melding-multiple-phi). 
__TODO:__ Swap this for a Zenodo DOI

### Results

```{r phi_subpost, fig.cap = "Subposterior credible intervals for $\\phi_{1 \\cap 2} = (\\alpha_{0}, \\alpha_{2})$ and $\\phi_{2 \\cap 3} = \\rho$ from the original integrated population model $\\pd_{\\text{ipm}}$, the melded posterior using the parallel sampler $\\pd_{\\text{meld}}$, the melded posterior using the normal approximation $\\widehat{\\pd}_{\\text{meld}}$, and the individual submodels $\\pd_{1}, \\pd_{2}$, and $\\pd_{3}$. Intervals are 50\\%, 80\\%, 95\\%, and 95\\% wide."}
knitr::include_graphics("plots/owls-example/subposteriors.pdf")
```

```{r phi_qq_compare, fig.cap = "Quantile-Quantile plot of ($\\phi_{1 \\cap 2}, \\phi_{2 \\cap 3}$) for the IPM posterior (y-axis) and melded posterior (x-axis). The empirical quantiles are displayed as a solid red line, and the optimal quantile is shown as a dashed black line. The melded posterior quantiles obtained using the normal approximation are plotted as a dot-dash blue line."}
knitr::include_graphics("plots/owls-example/orig-meld-qq-compare.pdf")
```
We empirically validate our methodology and sampler by comparing the melded posterior samples to the original IPM posterior.
Results are compared to a long run, 6 chains of $2 \times 10^5$ iterations each, of the original IPM code which we treat as the 'truth'.
The results obtained from our sampler are indistinguishable from the original IPM.
Figure \ref{fig:phi_subpost} depicts the posterior credible intervals [@gabry_bayesplot_2021; @kay_tidybayes_2020] for the melded quantities, and we are particular interested in the agreement between $\pd_{\text{meld}}$ $\pd_{\text{IPM}}$.
We further compare the IPM and melded posteriors via the QQ plots in Figure \ref{fig:phi_qq_compare}, and again see near identical results.
Trace plots, rank plots, and numerical convergence measures [@vehtari_rank-normalization_2020-1] for both stages of the parallel sampling process are presented in Appendix \ref{diagnostics-for-the-owls-example}.

Our sampling process gives back identical results to that of the original IPM.
It does so whilst combining a number of different Bayesian inference methods and implementations.
By no means is this the only combination of tools that could be used, it is merely illustrative of the idea developed here: we can use the output from one model to target some larger model, without needing to reimplement said model in a different language or framework.
It is also an example of estimating an intricate model without ever simultaneously evaluating all components of the model, a useful property for large, complicated models.

## Uncertain event times in joint longitudinal and survival models.

Standard survival analyses consider the event times and censoring indicators as known, fixed quantities.
However, in some settings the survival times are contaminated with nontrivial measurement error [@gu_semiparametric_2015; @meier_discrete_2003; @oh_considerations_2018; @snapinn_survival_1998;@wang_integrative_2020], or are derived from a, possibly highly complex, model for some other measurable quantity of the individual [see @lee_threshold_2006 for a review; and @szczesniak_dynamic_2020 for recent application].
Integrating the output of such models into standard parametric or Cox proportional hazards survival models is challenging, but we believe it is made conceptually and computational easier by our chained melding framework.

The integration of complex regression models into survival models is routine in the Joint modelling framework [@rizopoulos_joint_2012].
Such model complexity is often warranted due to the wide variety of behaviours of the longitudinal process. 
The associated computational cost motivates two stage estimation procedures [@ye_semiparametric_2008; @mauff_joint_2020] which reduce the computation required.
Such two stage processes are, in effect, considering a separate submodel for the longitudinal data, and we do the same in our example.
We argue that considering the models for the event times and longitudinal process separately is not an unreasonable modelling choice, and choosing to unite them in the survival model is a natural application of the chained melding method.

To highlight the chained melding process, and not obscure it behind individual submodel complexity, we use simpler versions of the threshold crossing, survival, and longitudinal submodels.
We use a subject specific linear model with constant threshold, a parametric Weibull model, and a distinct linear subject specific linear model for the respective submodels.
Data are simulated in a manner that is realistic, but avoids multiple types of censoring in the survival model and missing data.

### Submodels

#### First submodel: Event submodel

The first submodel describes an observable process, and say that an event to occurs when the process crosses some threshold.
Consider individuals $i = 1, \ldots, N$ for whom we record $j = 1, \ldots, J_{i}$ measurements $z_{i, j}$ at times $t_{i, j}$, further denoting $\boldsymbol{z}_{i} = (z_{i, 1}, \ldots, z_{i, J_{i}})$ and $\boldsymbol{t}_{i}$ analogously.
We fit the following hierarchical linear regression model
\input{tex-input/surv-example/0020-submodel-one-model.tex}
Individuals are said to experience the event of interest $T^{*}_{i}$ when their fitted model crosses some threshold $\kappa$, which is to say $T^{*}_{i} = (\kappa -\beta_{0, i})\mathop{/} \beta_{1, i}$.
In addition, we censor the events at time $t = 1$ such that we only record event times $T_{i} = \min(T^{*}_{i}, 1)$ and event indicators $\delta_{i} = \boldsymbol{1}(T^{*}_{i} \in (0, 1))$.
Due to our simple regression model it is possible for $T^{*}_{i}$ to be less than zero.
However, we do not consider the possibility that events occur prior to $t = 0$, and in cases where $T^{*}_{i} < 0$ we set $T_{i} = 1$ and $\delta_{i} = 0$.
We also remark that even this simple definition for $T^{*}_{i}$ results in a  non-invertible link function; one cannot uniquely compute the values of $\beta_{0, i}$ and $\beta_{1, i}$ given $T^{*}_{i}$ and $\kappa$.
Hence we consider this submodel in stage 1 when estimating the chained melded posterior.

Figure \ref{fig:submodel_one_synthetic_plot} displays the simulated data and fitted model where we set $\kappa = 0.2$, and depict the subposterior $\pd_{1}(\phi_{1 \cap 2} \mid Y_{1})$ via the blue uncertainty intervals.
The simulation settings, which we discuss momentarily, have been chosen so that there is a mix of individuals who clearly experience the event ($i = 9, 31$), do not experience the event ($i = 1, 4$), and some where there is some uncertainty about their status at the censoring time ($i = 17, 25$).
Among those who experience the event, there is residual model uncertainty as to when the event actually occurs, which is important to quantify in subsequent survival models. 

- _Should figure 8 be a subset of individuals, but also plot their longitudinal data?_

To align this submodel with our notation we denote this submodels data as $Y_{1} = (\boldsymbol{t}_{1}, \ldots, \boldsymbol{t}_{N}, \boldsymbol{z}_{1}, \ldots, \boldsymbol{z}_{N})$ and common quantity $\phi_{1 \cap 2} = (T_{1}, \ldots, T_{N}, \delta_{1}, \ldots, \delta_{N})$, with $\psi_{1}$ defined to be all model parameters in Equation \eqref{eqn:submodel-one-model}.

```{r submodel_one_synthetic_plot, fig.cap = "First submodel. The 80\\% credible interval for each individuals event distribution, if the event occurs for that individual, is displayed in blue and is truncated to $t \\in [0, 1]$. The threshold $\\kappa$ is displayed as the horizontal dashed line. Individuals that truly experience the event are distinguished by a solid mean regression line, whilst event free individuals have a dotted line."}
knitr::include_graphics("plots/surv-example/submodel-one-posterior.pdf")
```

#### Second submodel: Survival submodel

- _in the thesis, there should be a brief discussion on the issues encountered when trying to compute this_.

Our second submodel is a standard parametric Weibull survival model with rate $\gamma$.
Say we observe a baseline covariate $w_{i}$ for each individual.
We define the hazard and survival probabilities at time $t$
\input{tex-input/surv-example/0030-submodel-two-hazard-general.tex}
where $\theta_{0}$ is an intercept, $\theta_{1}$ is the regression parameter for the baseline covariate, and $\alpha$ quantifies the strength of the association between the event time and the fitted value from the longitudinal model $m_{i}(t)$, which we will define momentarily.
The log-likelihood is proportional to $\boldsymbol{1}_{\{\delta_{i} = 1\}} h_{i}(t) + S_{i}(t)$.
We complete the model by specifying the following priors
\input{tex-input/surv-example/0033-surv-model-priors.tex}
where $\overline{T}$ is the log of the crude event rate, in line with @brilleman_bayesian_2020.
Note that the model in Equation $\eqref{eqn:surv-model-priors}$ is written in terms of generic event time $t$, but we will consider uncertain event times for each individual $T_{i}$ from submodel 1.

In melding notation we have $Y_{3} = (w_{1}, \ldots, w_{N})$, and $\psi_{2} = (\gamma, \theta_{0}, \theta_{1}, \alpha)$. The common quantities, $\phi_{1 \cap 2}$ and $\phi_{2 \cap 3}$ are defined in previous and following sections respectively.

#### Third submodel: Longitudinal submodel

The third submodel is the longitudinal submodel. 
Specifically, we collect $k = 1, \ldots, K_{i}$ longitudinal observations for each individual $x_{i, k}$ at times $\tau_{i, k}$, which are not necessarily the same as the observations times in the event submodel $t_{i, j}$.
We stack each individuals observations and observation times in appropriate vectors $\boldsymbol{x}_{i} = (x_{1}, \ldots, x_{K_{i}})$ and $\boldsymbol{\tau}_{i} = (\tau_{1}, \ldots, \tau_{K_{i}})$.
The model is
\input{tex-input/surv-example/0040-submodel-three-model.tex}
and we define $m_{i}(t) = \eta_{0, i} + \eta_{1, i}t$. 
Note that this form of $m_{i}(t)$ requires numerical integration to obtain the survival probability in Equation \eqref{eqn:submodel-two-hazard-general}.

In our notation we denote data $Y_{3} = (\boldsymbol{x}_{1}, \ldots, \boldsymbol{x}_{N})$, and define the common quantity to be the parameters governing $m_{i}(t)$, i.e. $\phi_{2 \cap 3} = \boldsymbol{\eta} = (\eta_{0, 1}, \ldots, \eta_{0, N}, \eta_{1, 1}, \ldots, \eta_{1, N})$. 
The remaining parameters are absorbed into $\psi_{3} = (\mu_{\eta, 0}, \mu_{\eta, 1}, \sigma_{\eta, 0}, \sigma_{\eta, 1}, \sigma_{x})$.

#### Pooled prior:

- What are we going to do about it?
- exchangeable individuals means the prior marginals are $\pd_{1}(\phi_{1 \cap 2})^{N}$ and $\pd_{3}(\phi_{2 \cap 3})^{N}$.
- What on earth is $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$?
    - particularly $\pd_{2}(\phi_{1 \cap 2})$, the prior distribution for the event times and indicators in the survival model? 
    - there is a suite a methodology for simulating realistic event times from a survival model i.e. @crowther_simulating_2013. Can we repurpose this to sample from the prior?
        - Or, we can be lazy and use MCMC as $N$ is small.
- Just do PoE and not worry about it.

### Simulation details

Because we have multiple models for the common quantities, the joint model obtained via the product of the independent submodels is not generative.
As simulating from the prior predictive distribution is not possible, we need to choose how we generate synthetic data.
We do so by first simulating a latent event indicator for each of $N = 36$ individuals, then joint simulating the relevant submodel parameters.

Specifically, we first simulate a latent indicator variable $E_{i} \sim \text{Bern}(0.5)$ which is 1 if individual $i$ truly experiences the event of interest, and is 0 otherwise.
If $E_{i} = 1$, the critical parameters and covariates $(\beta_{1, i}, w_{i}, \eta_{0, i}, \eta_{1, i})$ are simulated from a multivariate normal distribution with mean $(1.5, 5, 3, 1.5)$ and covariance $\Sigma = \boldsymbol{I} + \boldsymbol{C}$, where $\boldsymbol{I}$ is the identity matrix and $\boldsymbol{C}$ is a matrix with non-diagonal entries of $0.5$ and diagonal entries of $0$.
Alternatively, if $E_{i} = 0$, all elements of $(\beta_{1, i}, w_{i}, \eta_{0, i}, \eta_{1, i})$ are independently simulated from standard normal distributions.

Observation times $\boldsymbol{t}_{i}$ and $\boldsymbol{\tau}_{i}$ are uniformly distributed between 0 and 1, and the number of observations $J_{i}$ and $K_{i}$ are uniformly distributed on the integers between 2 and 8 inclusive.

Remaining parameters and submodel data are simulated conditionally given the critical parameters. 
In submodel 1, the random intercept $\beta_{0, i}$ is simulated from $\text{N}(1, 0.1^2)$, and observations are then simulated such that $\boldsymbol{z}_{i} \sim \text{N}(\beta_{0, i} + \beta_{1, i}\boldsymbol{t}_{i}, 0.1\boldsymbol{I})$.
We simulate observations in submodel 3 such that $\boldsymbol{x}_{i} \sim \text{N}(\eta_{0, i} + \eta_{1, i}\boldsymbol{\tau}_{i}, \boldsymbol{I})$.

### Estimation and results

#### Estimation

The chained posterior is estimated using the parallel sampler.
In addition, the stage two Metropolis-within-Gibbs sampler updates each individual in $\phi_{1 \cap 2}$ separately, also in a Metropolis-within-Gibbs manner.
Such a proposal scheme is not obviously correct, so we show that it targets the desired chained posterior in Appendix BLAH.
All submodels are implemented in `Stan`[^stanver]; The stage one subposteriors are sampled using `Stan`'s dynamic HMC algorithm, and we use the `log_prob` function from `rstan` to evaluate the survival submodel in stage two.
All MCMC samplers consist of 5 chains of 5000 iterations each. The stage one samplers add an additional 1000 warmup iterations, which are discarded.
Numerical diagnostics including the split-$\widehat{R}$, bulk and tail effective sample sizes from @vehtari_rank-normalization_2020-1 are provided in Appendix \ref{diagnostics-for-the-survival-example}, as well as visual diagnostics of parameters with the worst numerical diagnostics.

[^stanver]: Submodel 2 requires numerical integration, which is performed using the `Stan` function `integrate_1d`. Previous versions of `Stan` report numerical errors when performing this integration, so we require a `Stan`/`rstan` version of `2.26` or higher. At the time of writing this version of `rstan` is not on `CRAN`, but sources and binaries can be obtained from the `stan-dev` GitHub.

<!--  _Need to think about where to put this?_ -> I think it should go here? Maybe in the discussion?
    However, as @mauff_joint_2020 note, commonly employed versions of the two-stage estimation process produce biased results. 
    In @mauff_joint_2020 this bias is removed via importance sampling with appropriate weights, which is similar to our two stage sampler in Section -->

#### Results

To understand the impact and importance of accounting for uncertainty in the event times and longitudinal submodel parameters, we compare the posterior distribution for the survival submodel parameters $\psi_{2}$ in four different settings:

1. The chained melded posterior, which accounts for the uncertainty in both $\phi_{1 \cap 2}$ and $\phi_{2 \cap 3}$.
1. Fixing $\phi_{1 \cap 2}$ and $\phi_{2 \cap 3}$ to their respective subposterior medians. Note that fixing $\phi_{1 \cap 2}$ to its posterior mean would be nonsensical, as it results in non-integer values for the $\delta_{i}$s.
1. Fixing $\phi_{1 \cap 2}$ and melding over $\phi_{2 \cap 3}$, which accounts for only the uncertainty in the longitudinal submodel.
1. Fixing $\phi_{2 \cap 3}$ and melding over $\phi_{1 \cap 2}$, which accounts for only the uncertainty in the event time submodel.

Figure \ref{fig:psi_2_comparison} displays the density estimates of the four aforementioned posterior distributions.
We see that accounting for the uncertainty in the event time submodel is critical, as the two posterior distributions with fixed $\phi_{1 \cap 2}$ are overconfident and biased.
In this straightforward example accounting for the uncertainty in $\phi_{2 \cap 3}$ appears seems less important. 
The difference between the chained melded posterior and the posterior with $\phi_{2 \cap 3}$ fixed is minimal, however a small difference between the posteriors is visible for $\alpha$.

```{r psi_2_comparison, fig.cap = "Comparison of posterior distributions of $\\psi_{2}$ using chained melding, propagating the subposterior median of $\\phi_{1 \\cap 2}$ and $\\phi_{2 \\cap 3}$ into stage two, and combinations thereof."}
knitr::include_graphics("plots/surv-example/psi-2-method-comparison.pdf")
```


```{r kaplan_meier_pc, fig.cap = "Survival probabilities for chained melded posterior and the posterior with both $\\phi_{1 \\cap 2}$ and $\\phi_{2 \\cap 3}$ fixed. The black lines are the Kaplan-Meier curves obtained using 500 representative stage two samples of $\\phi_{1 \\cap 2}$ from the chained melded posterior. The intervals are 80\\% posterior intervals, and the central lines are posterior means of average survival probability. The quantities relevant to the chained melded posterior are coloured red, and the fixed posterior blue."}
knitr::include_graphics("plots/surv-example/kaplan-meier-pc.pdf")
```

- I don't full believe Figure \ref{fig:kaplan_meier_pc} just yet. There is something going wrong numerically in the posterior predictive computations that I haven't figured out just yet

# Discussion

We have introduced the chained melded model, and illustrated the process by which multiple sources of information are combined to obtained the chained melded posterior.
Our examples demonstrate that practitioners are combining multiple sources of information in this 'chained' way, and that ignoring the uncertainty in any submodel component can produce biased, over-confident inference.
- Rehash what exactly we got out of the examples -- simple cases, framework makes it conceptually easier?

One contribution of this work is to make explicit the often informal process of summarising and/or approximating submodels for use in subsequent analyses.
The two most common, we believe, approximation strategies are
    1. Approximating the subposterior of the common quantity with a normal distribution, which is reused as a prior in stage two.
    2. Taking only a point estimate of the subposterior, and treating it as data in stage two.
These strategies may, but not always, produce acceptable approximations to the chained melded model.
It is interesting to note that many 'preprocessing' steps in an analysis pipeline can be thought of as 'summary by point estimate', where data are denoised or otherwise cleaned via models for future use. 
Such strategies are implementations of 'multi-phase' inference [@lin_trio_2014], and present additional statistical issues not discussed here.

- Discussion of estimation methods
- refines other components of submodels, where as using a parametric approximation to subposterior as a prior in latter models does not

_some discussion of seq/para_

- One distinction we explore is between the sequential integration of information and considering all submodels in parallel, i.e. what should one do if an additional submodel becomes available in the future?
    - What assumptions must be satisfied for the process to be 'exchangeable' w.r.t the order in which data become available? 
- We describe the independence criteria necessary for the sequential process to yield the same posterior as the chained melded model, and note that in general they do not yield the same posterior.
    - How should one set $\pd_{1}(\phi_{1 \cap 2})$ when one does not yet know what $\pd_{2}, \pd_{3},  \ldots$ are? Or set $\pd_{\text{pool}}$ when only $\pd_{1}, \pd_{2}$ are known, but there an unknown number of additional models to consider?
    - issue is with prior specification in the absence of other models, which is then too concentrated / in appropriate when other, related models are added is similar to the issue discussed in Section 4.4.3 of @jacob_better_2017-1.
- This is related to the idea that an inference process can/should be externally Bayesian, where by combining the data first then updating all the priors, should give the same result as independently updating the priors then combining the resulting posteriors.
    - Such a concept is not immediately applicable here, as it asks the process to satisfy strange criteria such as $\pd_{1}(\phi_{1 \cap 2} \mid Y_{3})\pd_{2}(\phi_{1 \cap 2} \mid Y_{3}) = \pd_{\text{meld}}^{12}(\phi_{1 \cap 2} \mid Y_{3})$ among others?

## Disadvantages

- Submodels may conflict with each other
    - Though we wouldn't have detected this if we could directly evaluate the joint.
- submodels may be practically unidentifiable
- Not all intermediary distributions/outputs are meaningful, depends on what we choose to sample at what stage. 

## Conflict

- Hopefully I'll address this in the next chapter

<!-- -------------------- END OF MAIN BODY OF DOCUMENT -------------------- -->
\newpage

<!-- The {-} tag here suppresses the section numbering. -->
# Bibliography {-}

<!-- This makes pandoc-citeproc put the references before the end of document. -->
<div id="refs"></div>

\newpage

<!-- Now switch to alphabetical numbering for the appendix, and reset the counter. -->
\renewcommand{\thesection}{\Alph{section}}
\setcounter{section}{0}

# General $\Nm$ case of the melded model, pooled priors.

## Model

Denote $\boldsymbol{\phi} = (\phi_{1 \cap 2}, \ldots, \phi_{\Nm - 1 \cap \Nm}), \boldsymbol{\psi} = (\psi_{1}, \ldots, \psi_{\Nm})$, and $\boldsymbol{Y} = (Y_{1}, \ldots, Y_{\Nm})$.
The $\Nm$ model chained melded model is 
\input{tex-input/multiple-phi/0011-melded-model-general.tex}

## Pooled prior

#### Linear pooling

The general $\Nm$ model linear pooled prior is
\input{tex-input/multiple-phi/0080-M-model-linear-pooling.tex}
where, for $\modelindex \neq 1$,
\input{tex-input/multiple-phi/0081-M-model-linear-pooling-marg.tex}

#### Logarithmic pooling

The general $\Nm$ model logarithmic pooled prior is
\input{tex-input/multiple-phi/0090-M-model-logarithmic-pooling.tex}

# Log pooling Gaussian densities

We can precisely compute $\pd_{\text{pool}}$ when logarithmically pooling Gaussian densities.
Noting that, in the one dimensional case, $\text{N}(\phi; \mu, \sigma^2)^{\lambda_{\modelindex}} = \text{N}(\phi; \mu, \frac{\sigma^2}{\lambda_{\modelindex}})$, we use the results of @bromiley_products_2003 and write
\input{tex-input/multiple-phi/0070-log-pooling-gaussian.tex}
hence $\pd_{\text{pool}}(\phi_{1 \cap 2}, \phi_{2 \cap 3}) = \text{N}(\left[\phi_{1 \cap 2} \,\, \phi_{2 \cap 3}\right]^{\top}\hspace{-0.5em};\, \mu_{\text{log}}, \, \Sigma_{\text{log}})$.
The choice of $\lambda_{2}$ is critical; by controlling the contribution of $\pd_{2}$ to $\pd_{\text{pool}}$, $\lambda_{2}$ controls the degree of correlation present in the latter.
The left hand column of Figure \ref{fig:pooled_densities_plot} illustrates this phenomena.
When $\lambda_{1} = \lambda_{3} = 0 \implies \lambda_{2} = 1$, all correlation in $\pd_{2}$ is present in $\pd_{\text{pool}}$.
The correlation decreases for increasing values of $\lambda_{1}$ until $\lambda_{1} = \lambda_{3} = 0.5 \implies \lambda_{2} = 0$, where no correlation persists.

# Diagnostics for the owls example

## Stage one diagnostics

\input{tex-input/owls-example/appendix-info/0010-stage-one-diagnostics.tex}

```{r stage_one_mcmc_trace_capture_recapture, fig.cap = "Stage one trace plot of $\\phi_{1 \\cap 2}$ in the capture recapture submodel."}
knitr::include_graphics("plots/owls-example/stage-one-diagnostics-capture-recapture.png")
```

```{r stage_one_mcmc_trace_fecundity, fig.cap = "Stage one trace plot of $\\phi_{2 \\cap 3}$ in the fecundity submodel."}
knitr::include_graphics("plots/owls-example/stage-one-diagnostics-fecundity.png")
```

## Stage two diagnostics

\input{tex-input/owls-example/appendix-info/0020-stage-two-diagnostics.tex}

```{r stage_two_mcmc_diags, fig.cap = "Stage two trace and rank plots of $\\phi_{1 \\cap 2}$ and $\\phi_{2 \\cap 3}$."}
knitr::include_graphics("plots/owls-example/stage-two-diagnostics.png")
```

\newpage

# Diagnostics for the Survival example

## Stage one diagnostics

### Numerical diagnostics

\input{tex-input/surv-example/0080-submodel-one-numeric-diags.tex}
\input{tex-input/surv-example/0081-submodel-three-numeric-diags.tex}

### Visual diagnostics

```{r stage_one_submodel_one_diag, fig.cap = "Stage one trace and rank plots for the parameters in both $\\psi_{1}$ and $\\phi_{1 \\cap 2}$ with the worst $\\widehat{R}$ and $N_{\\text{eff}}$"}
knitr::include_graphics("plots/surv-example/stage-one-submodel-one-diags.png")
```

```{r stage_one_submodel_three_diag, fig.cap = "Stage one trace and rank plots for the parameters in both $\\psi_{3}$ and $\\phi_{2 \\cap 3}$ with the worst $\\widehat{R}$ and $N_{\\text{eff}}$"}
knitr::include_graphics("plots/surv-example/stage-one-submodel-three-diags.png")
```

## Stage two diagnostics

### Numerical diagnostics

\input{tex-input/surv-example/0090-stage-two-phi-12-diag.tex}
\input{tex-input/surv-example/0091-stage-two-phi-23-diag.tex}
\input{tex-input/surv-example/0092-stage-two-psi-2-diag.tex}

### Visual diagnostics

```{r surv_ex_stage_two_diag_phi_12, fig.cap = "Stage two trace and rank plots for the parameters in $\\boldsymbol{\\phi}_{1 \\cap 2}$ with the worst $\\widehat{R}$ and $N_{\\text{eff}}$"}
knitr::include_graphics("plots/surv-example/stage-two-phi-12-diags.png")
```

```{r surv_ex_stage_two_diag_phi_23, fig.cap = "Stage two trace and rank plots for the parameters in $\\boldsymbol{\\phi}_{2 \\cap 3}$ with the worst $\\widehat{R}$ and $N_{\\text{eff}}$"}
knitr::include_graphics("plots/surv-example/stage-two-phi-23-diags.png")
```

```{r surv_ex_stage_two_diag_psi_2, fig.cap = "Stage two trace and rank plots for the parameters in $\\boldsymbol{\\psi}_{2}$ with the worst $\\widehat{R}$ and $N_{\\text{eff}}$"}
knitr::include_graphics("plots/surv-example/stage-two-psi-2-diags.png")
```
