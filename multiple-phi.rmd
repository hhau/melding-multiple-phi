---
title: "Multiple models, multiple shared quantities"
author: "Andrew Manderson"
date: "`r format(Sys.time(), '%d %B, %Y')`"
fontfamily: tgpagella
fontsize: 10pt
papersize: a4
geometry: margin=2.25cm
bibliography: bibliography/multi-phi-bib.bib
csl: bibliography/journal-of-the-royal-statistical-society.csl
output: 
  pdf_document:
    includes:
      in_header:
        tex-input/pre.tex
    fig_caption: true
    number_sections: true
    keep_tex: true
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, comment = NA, out.width = "99%", fig.align = "center", auto_pdf = TRUE)
```

# Introduction

- Considering multiple, diverse data presents a substantial challenge for statisticians [@donnat:etal:20].
    - If the data differ in structure, contain different types of measurements, or target related but non-identical populations of interest, then specifying a coherent joint model for each source of data presents a substantial challenge.
    - A more feasible approach may be to specify, and validate, individual submodels for each source of data, then combine 

- Computation for multiple models is also challenging
    - The computational effort required to fit a complex, multi-response model may prove prohibitive.
    - If instead we consider the submodel as the minimum computational unit, we may be able to parallelise certain aspects of the computation, and uses less expensive computational techniques for some submodels.
    - The melding framework also allows us to reuse the submodel computation when targeting the bigger joint model.
    - In a sense we would like to do Sequential importance sampling / refine our estimates, without needing to re-evaluate the submodels.
    - Also like to better understand each submodel, and each submodels contribution to the join model.

- Applied researches often collect multiple disparate data sets, and wish to combine them after the fact
    - Describe why and what they do
    - We are presenting a more formal, general form of the things that are done already

- Markov melding introduction
    - @goudie:etal:18 introduced Markov melding, a methodology for combining probabilistic models in a principled way. 
    - The aforementioned applied research does not always fit into the Markov melding methodology, which explicitly requires all $\Nm$ submodels to have the same quantity $\phi$ in common. 
    - In the applications we consider, we have a number of submodels that share quantities in a pair wise manner. <!-- Not clear what this means, cut straight to next sentence -->
    - Specifically, our examples contain 3 submodels $\pd_{\modelindex}, \modelindex = 1 \ldots, 3$; where submodel 1 and 2 share a common quantity $\phi_{1 \cap 2}$, and submodel 2 and 3 share a common quantity $\phi_{2 \cap 3}$. 
    - We will demonstrate that Markov melding, as introduced in @goudie:etal:18, is not always appropriate for joining submodels related in this way, and we devise an extension to the melded model that permits the desired model combination.

    <!-- Figure \ref{fig:intro-dag} contains a DAG representation of the relationship between submodels, where nodes in the DAG are submodels, and edges are quantities common to the submodels. they connect.

    \input{tex-input/introduction/0001-intro-dag.tex} -->

<!-- - Why do we need new methodology? What problem are we solving. -->

- Other advantages to modularised inference
    - understand submodels
    - use multiple software packages, which means we can reuse other computation
    - reuse posterior samples

# Example introduction

- We will now outline two applications that combine three submodels in the manner described in the introduction.

## An Integrated population model for little owls

Integrated population models (IPMs) [@zipkin:saunders:18] allow for precise estimation of population level quantities.
@schaub:etal:06 and @abadi:etal:10 use an IPM to estimate fecundity, immigration, and yearly survival rates for a population of little owls.
They collect three types of data: nest-record, population count, and capture-recapture, which collectively inform fecundity, immigration, and yearly survival rates.
Independent submodels are constructed for each source of data, and the IPM is the product of these independent submodels.
This model combination step is prudent; no single source of data is sufficient to estimate all quantities of interest.
The population count submodel informs quantities in both the nest-record submodel and the capture-recapture submodel, but the latter two submodels share nothing in common.
Information can be shared across all submodels through the population count submodel, which we can intuit from the DAG in Figure \ref{fig:owls-simple-dag}.
We will show that this example, and IPMs in general, can be expressed in the Markov melding framework developed in Section \ref{model-specification}.

\input{tex-input/owls-example/0001-owls-simple-dag.tex}

## other-tba

# Model specification

Our intention is to combine submodels into an appropriate joint model, which we call the melded model.
Explicitly, we consider $\modelindex = 1, \ldots, \Nm$ submodels each with distinct data $Y_{\modelindex}$ and parameters $\psi_{\modelindex}$.
Additionally, each submodel shares some quantity in common with another submodel $\phi_{\modelindex \cap \modelindex'}$, where $\modelindex \neq \modelindex'$.
<!-- We denote the $\modelindex^{\text{th}}$ submodel as $\pd_{\modelindex}(\phi_{\modelindex - 1 \cap \modelindex}, \phi_{\modelindex \cap \modelindex + 1}, \psi_{\modelindex}, Y_{\modelindex})$. -->
Our particular interest is in the $\Nm = 3$ submodel case, where submodels $\pd_{1}(\phi_{1 \cap 2}, \psi_{1}, Y_{1})$ and $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3}, \psi_{2}, Y_{2})$ have $\phi_{1 \cap 2}$ in common, and $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3}, \psi_{2}, Y_{2})$ and $\pd_{3}(\phi_{2 \cap 3}, \psi_{3}, Y_{3})$ both contain $\phi_{2 \cap 3}$.
<!-- TODO: -->The appendix contains the more general $\Nm$-model case.
Each submodel is assumed to be a valid joint density function over all relevant quantities, and all submodel conditionals exist with appropriate support.

## Melded model

<!-- Do we need to call this model something else? It's quite confusing having both this model and the original paper's model be called the 'melded model'. -->

The joint model under investigation here is an extension the melded model introduced in @goudie:etal:18.
To emphasise that we are interested in a valid joint density, we first express the melded model in terms of submodel specific conditional distributions
\input{tex-input/multiple-phi/0010-melded-model-cond.tex}
By conditioning on the common quantities in each submodel, and assuming that the prior for $(\phi_{1 \cap 2}, \phi_{2 \cap 3})$ is proper, we are sure that the joint density is a valid joint density function.
We will return to the prior on $(\phi_{1 \cap 2}, \phi_{2 \cap 3})$ in Section \ref{pooled-prior}.

The conditional distributions of Equation \eqref{eqn:melded-model-cond} are not always available.
However, each conditional distribution can be written in terms of the submodel joint density and appropriate marginal, and we rewrite the right hand side of Equation \eqref{eqn:melded-model-cond} as
\input{tex-input/multiple-phi/0012-melded-model-full.tex}
We refer to Equation \eqref{eqn:melded-model-full} as the melded model, and note that it is proportional to the melded posterior $\pd_{\text{meld}}(\phi_{1 \cap 2}, \phi_{2 \cap 3}, \psi_{1}, \psi_{2}, \psi_{3} \mid Y_{1}, Y_{2}, Y_{3})$.

## Pooled prior

Obtaining posterior estimates of the parameters requires us to specify a prior distribution for $(\phi_{1 \cap 2}, \phi_{2 \cap 3})$.
Specifying joint priors is difficult, and we have the additional complication that $\phi_{1 \cap 2}$ and $\phi_{2 \cap 3}$ may have different supports.
However, because we are combining submodels we can use the prior information available in each submodel.
We form our joint prior by _pooling_ [@ohagan:06] together the relevant submodel prior marginal distributions: $\pd_{1}(\phi_{1 \cap 2}), \pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$, and $\pd_{2}(\phi_{2 \cap 3})$, and denote the result as the _pooled prior_ $\pd_{\text{pool}}$.
In this section we apply, and where necessary extend, linear and logarithmic pooling for use in the melded model.

Throughout we assume that $\pd_{1}(\phi_{1 \cap 2}), \pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$, and $\pd_{2}(\phi_{2 \cap 3})$ are normalised, integrable probability density functions, that $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$ admits proper marginals for $\pd_{2}(\phi_{1 \cap 2})$ and $\pd_{2}(\phi_{2 \cap 3})$, and proper conditionals for $\pd_{2}(\phi_{1 \cap 2} \mid \phi_{2 \cap 3})$ and $\pd_{2}(\phi_{2 \cap 3} \mid \phi_{1 \cap 2})$.
For simplicity we will also assume that $\phi_{1 \cap 2} \in \mathbb{R}^{d_{1}}$ and $\phi_{2 \cap 3} \in \mathbb{R}^{d_{2}}$, and the supports of $\pd_{1}(\phi_{1 \cap 2}), \pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$, and $\pd_{2}(\phi_{2 \cap 3})$ are $\mathbb{R}^{d_{1}}, \mathbb{R}^{d_{1}} \times \mathbb{R}^{d_{2}}$, and $\mathbb{R}^{d_{2}}$ respectively.

### Linear pooling

Linear pooling typically proceeds by taking a linear combination of submodel prior marginal densities.
However, linearly pooling densities with different supports can produce invalid pooled priors.
Specifically, consider the naive extension to linear pooling
\input{tex-input/multiple-phi/0052-linear-pooling.tex}
where each $\lambda_{\modelindex} \in \mathbb{R}^{+}$ is a submodel specific pooling weight. 
These weights are used when we believe the submodel prior marginal densities are not equally informative.
It is not obvious that this density is normalisable.
Indeed when integrating $\pd_{\text{pool}}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$
\input{tex-input/multiple-phi/00521-int-linear-pooling.tex}
we find that the first term of this integral
\input{tex-input/multiple-phi/00522-int-linear-pooling.tex}
is divergent due to the $\int_{\mathbb{R}^{d_{2}}}\text{d}\phi_{2 \cap 3}$ term.
Hence, the naive extension to linear pooling does not admit a proper probability density function, due to the different supports for $\phi_{1 \cap 2}$ and $\phi_{2 \cap 3}$.

We propose the following strategy, which is a two-step linear pooling approach.
The first step forms intermediary pooling densities via standard linear pooling, using appropriate marginals with common support
\input{tex-input/multiple-phi/0054-silly-linear-solution.tex}
Because we do not strictly require that $\lambda_{1, 1} + \lambda_{2, 1} = 1$, $\pd_{\text{pool}, 1}$ is not necessarily normalised by construction; likewise for $\pd_{\text{pool}, 2}$.
In step two we form the pooled prior as the product of the intermediaries
\input{tex-input/multiple-phi/0055-silly-linear-overall.tex}
Equation \eqref{eqn:silly-linear-overall} implies that our linear pooling process will always produce a pooled prior with no correlation between $\phi_{1 \cap 2}$ and $\phi_{2 \cap 3}$, which may be undesirable.
It is possible to induce correlation between independent marginal distributions via copulas [@nelsen:06] and other techniques [@lin:etal:14], but these methods are less intuitive than capturing dependence in the pooling process.

### Logarithmic pooling.

A multiplicative alternative to linear pooling is logarithmic pooling.
Products of densities with different supports are common in statistical modelling, and typically result in proper density functions.
We define the logarithmically pooled prior to be 
\input{tex-input/multiple-phi/0050-pooled-prior-overall.tex}
This is a valid probability density function for $\pd_{\text{pool}}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$, due to our assumption that all prior marginal distributions are proper and finitely integrable. 
Unlike linear pooling, correlation present in $\pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$ will persist in $\pd_{\text{pool}}$.

### Pooling weights

We are interested in specifying a prior that accurately and robustly expressed our prior beliefs.
Choosing the pooling method and parameters lambda are akin to choosing the prior and hyperparameters; specifying $\lambda = (\lambda_{1}, \lambda_{2}, \lambda_{3})$ is particularly challenging part of the modelling process.
Using linear pooling to construct $\pd_{\text{pool}}$ allows us to interpret $\lambda$ as a vector of mixture weights [@everitt:hand:81; @genest:mcconway:90].
However, when employing logarithmic pooling, the components of $\lambda$ are not interpretable as weights in the mixture density sense. 
We would like to develop our intuition about the influence of $\lambda$ on $\pd_{\text{pool}}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$, particularly when using logarithmic pooling, so that our choice of $\lambda$ appropriately reflects our prior information.
We pool some simple prior marginal distributions, and simulate from $\pd_{\text{pool}}$ produced using different values of $\lambda$ as a prior predictive check.

- _something about giving $\lambda$ a prior leading to a doubly-intractable problem [@moller:etal:06]?._

#### Choosing relative values for the weights

Consider pooling the following prior marginal distributions
\input{tex-input/multiple-phi/0061-marginal-gaussian-example.tex}
where $f(\phi; \mu, \sigma^{2})$ is a density function with location parameter $\mu$, scale parameter $\sigma$, and $f$ is an appropriate dimension Gaussian or Student-$t_{4}$ density function.
The two dimensional density function $\pd_{2}$ has an additional parameter $\rho$, which controls the correlation.
Appendix \ref{log-pooling-gaussian-densities} derives $\pd_{\text{pool}}$ when all densities being pooled are Gaussian and logarithmic pooling is employed. This derivation emphasises the importance of $\lambda_{2}$, it controls the degree of correlation present in $\pd_{\text{pool}}$.
In all other cases a recognisable form for $\pd_{\text{pool}}$ is not derivable, and we estimate $\pd_{\text{pool}}$ via numerical methods.

To understand the effect of $\lambda$ on $\pd_{\text{pool}}$ we set fix the parameters in the densities in Equation \eqref{eqn:marginal-gaussian-example} whilst varying $\lambda$.
We set $\mu_{1} = -2, \mu_{2} = \left[\mu_{2, 1} \,\, \mu_{2, 2}\right]' = \left[0 \,\, 0\right]', \mu_{3} = 2, \sigma_{1}^{2} = \sigma_{2}^{2} = \sigma_{3}^{2} = 1$ and $\rho = 0.8$.
For simplicity, in the logarithmic case we set $\lambda_{1} = \lambda_{3}$ and parameterise $\lambda_{2} = 1 - 2\lambda_{1}$, so that $\lambda_{1} + \lambda_{2} + \lambda_{3} = 1$ whilst limiting ourselves to only varying $\lambda_{1}$.
Similarly, in the linear case we set $\lambda_{1, 1} = \lambda_{2, 2} = \lambda_{1}$ and $\lambda_{1, 2} = \lambda_{2, 1} = 1 - 2 \lambda_{1}$.

Figure \ref{fig:pooled_densities_plot} contains the estimates of $\pd_{\text{pool}}$ for $\lambda_{1} \in \{0, 0.1, 0.2, \frac{1}{3}, 0.45, 0.5\}$.
In the linear case $\pd_{\text{pool}}$ contains no correlation, due to the additive form of Equations \eqref{eqn:silly-linear-solution-1} and \eqref{eqn:silly-linear-solution-2}.
Also, the variance of $\pd_{\text{pool}}$ in the linear case increases as $\lambda_{1}$ increases from $0$ to $\frac{1}{3}$, then decreases as $\lambda_{1}$ increases further to $0.5$.
This behaviour is not intuitive, and pooled densities constructed via linear pooling should be thoroughly investigated to ensure they are fit for purpose before being used in the melded model.
Logarithmic pooling does not display this behaviour, for increasing values of $\lambda_{1}$ the variance of $\pd_{\text{pool}}$ consistently increases.
The $\lambda_{1} = 0.45$ case is noteworthy when using logarithmic pooling; the mode of $\pd_{\text{pool}}$ formed from $t_{4}$ densities has shifted towards the marginal mean $[-2 \,\, 2]'$ more so than the Gaussian equivalent.
Logarithmically pooled priors should also be checked for suitability a priori, as part of a Bayesian workflow [@betancourt:20].

```{r pooled_densities_plot, fig.cap = "Contour plots of $\\pd_{\\text{pool}}$ under linear and logarithmic pooling (columns), for the values of $\\lambda_{1}$ indicated in the row labels. The distributional form of $f$ corresponds to the colours of the contours."}
knitr::include_graphics("plots/pooling-tests/pooled-densities-2d.pdf")
```

#### Varying the dimension

```{r pooling_dimension_tests, fig.cap = "tba"}
knitr::include_graphics("plots/pooling-tests/densities-vs-dimension.pdf")
```
Intuition obtained in low dimensional settings does not generalise to higher dimensional ones, which makes choosing an appropriate $\lambda$ more challenging in the latter.
To illustrate this challenge, we consider $d$-dimensional versions of the Gaussian and Student-$t_{4}$ densities, with $d$ dimensional zero vector $0_{d}$ and identity matrix $\mathcal{I}_{d}$ as mean/location and covariance/scale respectively.
Denoting the density function of interest as $f(\phi_{d}; 0_{d}, \mathcal{I}_{d})$, we evaluate it at two points: $\phi_{d} = 0_{d}$, the mode of both densities, and $\phi_{d} = 2_{d}$, a point suitably far in the tails, for increasing values of $d$, and display the results in Figure \ref{fig:pooling_dimension_tests}.
The Gaussian density function decreases at an exponential rate, and the decrease occurs faster for the point in the tail.
In the Student-$t_{4}$ case, the density decreases exponentially when evaluated at $2_{d}$, however for $0_{d}$, the density function decreases to a minimum, and then increases at a faster-than-exponential rate.
This indicates that the behaviour of the Student-$t_{4}$ density, as a function of $d$, depends on where it is evaluated. 
We can deduce that, when pooling sufficiently non-Gaussian densities, the appropriate value for $\lambda$ depends on the range of values at which we evaluate $\pd_{\text{pool}}$.
Such information is generally unavailable a priori, emphasising the need to employ prior-predictive checks to ensure $\pd_{\text{pool}}$ appropriately represents available information.

# Posterior estimation

We now present two multi-stage MCMC methods for generating samples from the melded posterior.
By employing a multi-stage strategy we can avoid evaluating all submodels simultaneously.
This is desirable in situations where simultaneously evaluating the submodel terms is computationally infeasible or otherwise undesirable, whilst evaluating the prior marginal distributions is possible and relatively inexpensive.
The first sampler operates sequentially, accruing and refining samples by considering one submodel at a time.
The second parallelises parts of the sampling process, and has the potential to produce a sample, usable for inference, from the melded posterior in less time than the sequential method.

## Sequential sampler

Stage one ($s_{1}$) of the sequential sampler targets terms from submodel $\pd_{1}$. 
The target is expanded in stage two ($s_{2}$) to also include $\pd_{2}$ terms, finally to include $\pd_{3}$ terms and $\pd_\text{pool}$ in stage three ($s_{3}$).
An overview of this target broadening process is displayed in Figure \ref{fig:seq-sampler-dag}
\input{tex-input/multi-stage-sampler/0001-seq-sampler-dag.tex}
    
#### Stage one

Mathematically, stage one of the sequential sampler targets
\input{tex-input/multi-stage-sampler/0020-stage-one-target.tex}
using a generic proposal kernel for both $\phi_{1 \cap 2}$ and $\psi_{1}$. 
The corresponding acceptance probability for a proposed update from $(\phi_{1 \cap 2}, \psi_{1})$ to $(\phi_{1 \cap 2}^{*}, \psi_{1}^{*})$ is
\input{tex-input/multi-stage-sampler/0021-stage-one-acceptance-probability.tex}

#### Stage two

The stage two target augments the stage one target by including the second submodel and corresponding prior marginal distribution,
\input{tex-input/multi-stage-sampler/0030-stage-two-target.tex}
A Metropolis-within-Gibbs strategy is employed, where the stage one samples are used as a proposal for $\phi_{1 \cap 2}$, whilst a generic proposal kernel is used for $\psi_{2}$ and $\phi_{2 \cap 3}$.
Thus the proposal distributions for $\phi_{1 \cap 2}^{*}$ and $(\phi_{2 \cap 3}^{*}, \psi_{2}^{*})$ are 
\input{tex-input/multi-stage-sampler/0031-stage-two-gibbs-updates.tex}
The acceptance probability for this proposal strategy is
\input{tex-input/multi-stage-sampler/0032-stage-two-acceptance-probabilities.tex}
Our judicious choice of proposal distribution has resulted in a cancellation in Equation \eqref{eqn:stage-two-acceptance-probabilities-one} which removes all terms related to $\pd_{1}$.
Similarly, all terms related to $\pd_{1}$ are constant -- hence cancel -- in Equation \eqref{eqn:stage-two-acceptance-probabilities-two}.
This eliminates any need to re-evaluate the first submodel.

#### Stage three

In stage three we target the full melded posterior
\input{tex-input/multi-stage-sampler/0044-stage-three-target.tex}
The target has now been broadened to include terms from the third submodel and the pooled prior.
Again, we employ a Metropolis-within-Gibbs sampler, with proposals drawn such that
\input{tex-input/multi-stage-sampler/0045-stage-three-gibbs-updates.tex} 
which leads to acceptance probabilities of
\input{tex-input/multi-stage-sampler/0046-stage-three-acceptance-probabilities.tex}
The informed choice of proposal distribution for ($\phi_{1 \cap 2}, \phi_{2 \cap 3}, \psi_{1}, \psi_{2}$) has allowed us to target the full melded posterior without needing to evaluate all submodels simultaneously.  

## Parallel sampler

We now devise a strategy where stage one samples submodels 1 and 3 in parallel. Stage two reuses these samples in a Metropolis-within-Gibbs sampler, which targets the full melded posterior.
The stage specific targets are displayed in Figure \ref{fig:parallel-dag}.

\input{tex-input/dc-sampler/0001-parallel-dag.tex}

#### Stage one

Two independent, parallel sampling processes occur in stage one.
Submodels one and three are targeted
\input{tex-input/dc-sampler/0021-stage-one-targets.tex}
using submodel-specific transition kernels, leading to acceptance probabilities of
\input{tex-input/dc-sampler/0022-stage-one-acceptance-probs.tex}
which can be computed independently of one another.

#### Stage two

Stage two targets the melded posterior of Equation \eqref{eqn:melded-model-full} using a Metropolis-within-Gibbs sampler, where the proposals are distributed according to
\input{tex-input/dc-sampler/0031-stage-two-proposals.tex}
The acceptance probabilities for these updates are
\input{tex-input/dc-sampler/0032-stage-two-acceptance.tex}
Note that all stage two acceptance probabilities only contain terms from the second submodel and the pooled prior.

# Examples

## Little owls

We now return to the integrated population model (IPM) for the little owls introduced in Section \ref{an-integrated-population-model-for-little-owls}.
Because the population count model includes a parameter also contained in the nest-record model, and has two parameters in common with the capture-recapture model, the IPM can be viewed as a melded model, as described in Section \ref{melded-model}.
Viewing the IPM as a melded model allows us to use the parallel sampler described in Section \ref{parallel-sampler}.

### Submodels

@finke:etal:19 consider a number of variations on the original model of @schaub:etal:06 and @abadi:etal:10.
We consider variant from @finke:etal:19 with the highest marginal likelihood.
Before we detail the specifics of our chosen model, we need to introduce some notation. 
Data and parameters are stratified into two age-groups $a \in \{J, A\}$ where $J$ denotes juvenile owls and $A$ adults, Two sexes $s \in \{M, F\}$, and observations occur at times $t \in \{1, \ldots, T\}$, for $T = 25$.

#### Capture recapture: $\pd_{1}$

Capture-recapture data pertain to owls that are captured, tagged, and released at time $t$.
These individuals are then recaptured at time $u$, for $t + 1 < u < T + 1$, or not recaptured before the conclusion of the study, in which case $u = T + 1$. 
Define $M_{a, s, t, u}$ as the number of owls last observed at time $t$, recaptured at time $u$, of sex $s$, and age-group $a$.
These observations are then aggregated into age-group and sex specific matrices $\boldsymbol{M}_{a, s}$, with $T$ rows and $T + 1$ columns.
Let $R_{a, s, t} = \sum_{u = 1}^{T + 1} \boldsymbol{M}_{a, s, t, u}$ be the number of owls observed at time $t$ and then released, i.e. a vector containing the row-wise sum of the entries in $\boldsymbol{M}_{a, s}$.
The multinomial likelihood is
\input{tex-input/owls-example/0010-capture-recapture-submodel.tex}
with probabilities $\boldsymbol{Q}_{a, s, t} = \{Q_{a, s, t, u}\}_{u = 1}^{T + 1}$ such that
\input{tex-input/owls-example/0011-multinomial-probabilities.tex}

#### Count data model: $\pd_{2}$ 

To estimate population abundance, a two level model is used.
One level models the observed (counted) number of females at each point in time, with a second, latent process modelling the total number of females in population.
Denote the total number of juvenile and adult females in the population at time $t$ as $\mathbf{x}_{t} = \left[x_{J, t}, x_{A, t}\right]$.
The latent, population level model is 
\input{tex-input/owls-example/0020-count-data-submodel.tex}
Initial population sizes $(x_{J, 1}, x_{A, 1})$ are a priori uniformly distributed over $\{0, 1, \ldots, 50\}$.
The observation level model is  
\input{tex-input/owls-example/0021-observation-process.tex}

#### Fecundity: $\pd_{3}$

The fecundity submodel considers the number of breeding females at time $t$, $N_{t}$, and the number of chicks produced that survive and leave the nest $n_{t}$.
A Poisson model is employed, with fecundity (reproductive) rate $\rho$
\input{tex-input/owls-example/0030-fecundity-submodel.tex}
 
#### Parameterisation and melding quantities

@abadi:etal:10 parameterise the time dependent quantities via linear predictors, to minimise the number of parameters in the submodels.
However, our choice to use the 'best' model of @finke:etal:19 renders many of the quantities independent of time.
The specific parameterisation we employ is
\input{tex-input/owls-example/0040-parameterisation-info.tex}
thus the quantities common to the submodels are $\phi_{1 \cap 2} = (\alpha_{0}, \alpha_{2})$ and $\phi_{2 \cap 3} = \rho$.
Our definition of $\phi_{1 \cap 2}$ does not include $\alpha_{1}$ as it is male specific, and does not exist in $\pd_{2}$.
To align the notation of this example with the melding notation we define, for all permitted values of $a, s$ and $t$, $Y_{1} = \boldsymbol{M}_{a, s}$, $\psi_{1} = \pi_{s, t}$; $Y_{2} = y_{t}$, $\psi_{2} = (\boldsymbol{x}_{t}, \eta, \text{sur}_{t}, \text{imm}_{t})$; and $Y_{3} = (N_{t}, n_{t})$, $\psi_{3} = \varnothing$.
We use the priors of @abadi:etal:10 for the parameters in each submodel.
The components of $\alpha$ present in $\pd_{1}$ and $\pd_{2}$ are assigned independent $\text{N}(0, 100^2)$ priors which are truncated to $[-10, 10]$. 
A $\text{U}(0, 10)$ prior is assigned to $\rho$ in $\pd_{2}$ and $\pd_{3}$.

Completing the specification of $\pd_{\text{meld}}$ requires us to choose $\pd_\text{pool}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$.
So that we can appropriately compare the melded posterior with the IPM posterior $\pd_{\text{meld}}$ we opt for product-of-experts pooling: $\pd_\text{pool}(\phi_{1 \cap 2}, \phi_{2 \cap 3}) \propto \pd_{1}(\phi_{1 \cap 2}) \pd_{2}(\phi_{1 \cap 2}, \phi_{2 \cap 3}) \pd_{3}(\phi_{2 \cap 3})$.

- _Should I also run a variant that forms $\pd_{\text{pool}}(\phi_{1 \cap 2}, \phi_{2 \cap 3})$ via one of our pooling methods?_

### Posterior estimation via the parallel sampler

We use the parallel sampler introduced in Section \ref{parallel-sampler}.
This allows us to use pre-existing implementations of the submodels.
Specifically, the capture-recapture and count data submodels are written in BUGS [@lunn:etal:09], and the subposterior of the former is sampled via `rjags` [@plummer:19]. 
The fecundity submodel is written in Stan [@carpenter:etal:17] and sampled via `rstan` [@rstan:pacakge:20].
We reuse the count data BUGS implementation for stage two of the multi-stage sampler, and implement the Metropolis-within-Gibbs sampler specified in Section \ref{parallel-sampler} via Nimble [@devalpine:etal:2017] and its `R` interface [@nimble:package:19].
Code for this example is available at https://github.com/hhau/melding-owls-example.

### Results

```{r phi_subpost, fig.cap = "Subposterior credible intervals for $\\phi_{1 \\cap 2} = (\\alpha_{0}, \\alpha_{2})$ and $\\phi_{2 \\cap 3} = \\rho$ from the original integrated population model $\\pd_{\\text{ipm}}$, the melded posterior $\\pd_{\\text{meld}}$, and the individual submodels $\\pd_{1}, \\pd_{2}$, and $\\pd_{3}$. Intervals are 50\\%, 80\\%, 95\\%, and 95\\% wide."}
knitr::include_graphics("plots/owls-example/subposteriors.pdf")
```

```{r phi_qq_compare, fig.cap = "Quantile-Quantile plot of ($\\phi_{1 \\cap 2}, \\phi_{2 \\cap 3}$) for the IPM posterior (y-axis) and melded posterior (x-axis). The empirical quantiles are displayed as a solid red line, and the optimal quantile is shown in a dashed black line."}
knitr::include_graphics("plots/owls-example/orig-meld-qq-compare.pdf")
```
We empirically validate our methodology and sampler by comparing the melded posterior samples to the original IPM posterior.
Results are compared to a long run, 6 chains of $2 \times 10^5$ iterations each, of the original IPM code which we treat as the 'truth'.
The results obtained from our sampler are indistinguishable from the original IPM.
Figure \ref{fig:phi_subpost} depicts the posterior credible intervals [@gabry:etal:19; @kay:20] for the melded quantities, and we are particular interested in the agreement between $\pd_{\text{meld}}$ $\pd_{\text{IPM}}$.
We further compare the IPM and melded posteriors via the QQ plots in Figure \ref{fig:phi_qq_compare}, and again see near identical results.
Trace plots, rank plots, and numerical convergence measures [@vehtari:etal:diagnostics:19] for both stages of the parallel sampling process are presented in Appendix \ref{diagnostics-for-the-owls-example}.

Our sampling process gives back identical results to that of the original IPM.
It does so whilst combining a number of different Bayesian inference methods and implementations.
By no means is this the only combination of tools that could be used, it is merely illustrative of the idea developed here: we can use the output from one model to target some larger model, without needing to reimplement said model in a different language or framework.
It is also an example of estimating an intricate model without ever simultaneously evaluating all components of the model, a useful property for large, complicated models.

## uncertain event times and missing data in survival models

This is hopefully going to be the second example for the multiple phi chapter.

### Submodels


#### First submodel

This submodel has two steps.

1.  Can we get SF (SpO2/FiO2) ratio and PF (PO2/FiO2) ratio data for ICU patients.
    - One of these quantities is less available, but more desirable?
        - according to @pandharipande:etal:09, the PF ratio is the actual blood gas measurement of interest, but needs to be done in a lab. The SF ratio is more available as a result (requires non-invasive measurement).
    - Can we build a model that converts a SF ratio measurement to a PF ratio distribution.
    - get data from MIMIC? 
        - for the moment we can stick to synthetic data until all the submodels work
2. Can we then take each individuals uncertain PF ratio measurements, plot them over time (assuming there is a temporal aspect to these measurements), fit a regression model, look at the (mean/predictions?) from the regression model, see if/when they drop below a threshold (tau, definition of event occurring), and sample the distribution of event times for each individual. 
    - censoring?
    - for more complicated regression models (i.e. not linear regression), finding the event time (first time y goes below tau) will involve optimising? (if the inverse of the regression function is not available)

I simulate some synthetic data to address step 2 in Figure \ref{fig:submodel_one_synthetic_plot}.
Here we have measurements over time.
Modelling the trajectory allows us to sample the event time distribution for each patient.
The 80% credible interval for each patient's event time is in blue, with the caveat that I have truncated this distribution to [0, 1], and if both the upper and lower bound of the CI fall outside this interval, I have not plotted it.

Note that this means we get a distribution of event times for patients who clearly do not have the event.
I'm not sure this fits into a typical survival analysis framework?

- I think we should set the event time to $t = 1$ (the maximum possible time) when the event is censored (i.e. $T_{i}^{*} = C_{i} = 1$] when $\delta_{i} = \mathcal{I} \{T_{i}^{*} < C_{i}\} = 0$)

```{r submodel_one_synthetic_plot, fig.cap = "First submodel. The 80\\% credible interval for each individuals event distribution, if the event occurs for that individual, is displayed in blue and is truncated to $t \\in [0, 1]$."}
knitr::include_graphics("plots/surv-example/submodel-one-posterior.pdf")
```


#### Second submodel

- the second submodel uses these uncertain event times as a response to a survival model.
  - the phi/melding quantity here will be patient specific
- we might have baseline covariate information about these individuals, and we wish to find the posterior distribution of the coefficients (to see if any of the baseline covariates are indicative of the event occurring?)
  - for simplicity we should stick to baseline only (no repeated measures?)
- some of these may be missing, and we meld over the missing data?
  - the phi will be patient specific as well (and potentially quite tricky depending on how the missingness is structured).
    - MCAR makes everything independent? Means all KDEs (if necessary) are 1-d?
  - start with simulating covariates, and removing them randomly whilst ensuring that we don't completely remove patients.
- use a weibull/parametric survival model 
  - find out what the likelihood is for this:  (d/dt (1 - S(t))), where the weibull model defines the survival function S(t), and I can easily analytically compute the derivative.

- for time-varying covariates, this is joint longitudinal / survival modelling.
- We might want to do the longitudinal / trajectory modelling bit first? Evaluating the linear predictor $\eta_{i}(t)$ is still a little unclear to me. 

- We may want to do extra covariates at baseline in this submodel.
    - if we do time-varying covariates in the other submodel, then without additional baseline covariates $\pd_{2}$ only assembles other submodel components (i.e. $Y_{2} = \emptyset, \psi_{2} = \emptyset$)

#### Third submodel

- for time varying covariates, this submodel is (in the joint modelling world) referred to as the biomarker submodel.
- say we have $P = 3$ biomarkers / covariates, indexed by $p = 1, \ldots, P$. 
- for each covariate we should/could? have a mean trajectory (spline or polynomial of time), and each individual should have a deviation/spline-as-a-random effect from it? (splines and scaling is a problem here (new individuals outside scale? never predicting anyway, so doesn't matter)).
- the sampled spline coefficients then become $\phi_{2 \cap 3}$, because for the same spline basis they alone define the trajectory of the covariate/biomarker (mean or posterior predictive?)
- then we can evaluate $\eta_{i}(t) = f_{i}(t)$ (the predictor / spline fit / trajectory) at any value $t$.
    - however, there is a computational issue here
    - typically we precompute the b-spline basis for a fixed grid of evaluation points (not just knots), and write the spline term as a random effect $\boldsymbol{Z}u$. We'd have to recompute the spline basis each time we propose an event time $t$. 
        - this is true even if we use a truncated power basis or B-spline basis.
        - gp has same problem, would need to recompute kernel distance matrix for each new evaluation point.
    - if we did some kind of polynomial regression this would be less or a problem

### Diagnostics

### Results

# Discussion

## Sequential vs parallel sampler

## Advantages

- better understand submodels, and components thereof
    - priors / prior predictive distributions / posterior predictive distributions / posterior pathologies therein
- mostly re use existing implementations
- refines other components of submodels, where as using parametric approximation to subposterior as a prior in latter models does not.

## Disadvantages

- Submodels may conflict with each other
    - Though we wouldn't have detected this if we could directly evaluate the joint.
- submodels may be practically unidentifiable
- Not all intermediary distributions/outputs are meaningful, depends on what we choose to sample at what stage. 

## Why can't we do melding twice (need better name for section)

- Astute reader may ask why we cannot apply Markov melding twice - the answer is that ordering matters.   
    - Explaining why relies on too much notation for an introduction, and requires us to have introduced the new melded model.
    - It feels like a very weird detour to take before looking at examples, so I guess this has to go in the discussion? 
    - Maybe it should just be an appendix, with a brief note in the main text 
   
    - Get text tidy from earlier version.


## Conflict

- Hopefully I'll address this in the next chapter

# Conclusion 


<!-- -------------------- END OF MAIN BODY OF DOCUMENT -------------------- -->
\newpage

<!-- The {-} tag here suppresses the section numbering. -->
# Bibliography {-}

<!-- This makes pandoc-citeproc put the references before the end of document. -->
<div id="refs"></div>

\newpage

<!-- Now switch to alphabetical numbering for the appendix, and reset the counter. -->
\renewcommand{\thesection}{\Alph{section}}
\setcounter{section}{0}

# Log pooling Gaussian densities

We can precisely compute $\pd_{\text{pool}}$ when logarithmically pooling Gaussian densities.
Noting that, in the one dimensional case, $f(\phi; \mu, \sigma^2)^{\lambda_{\modelindex}} = f(\phi; \mu, \frac{\sigma^2}{\lambda_{\modelindex}})$, we use the results of @bromiley:03 and write
\input{tex-input/multiple-phi/0070-log-pooling-gaussian.tex}
hence $\pd_{\text{pool}}(\phi_{1 \cap 2}, \phi_{2 \cap 3}) = f(\left[\phi_{1 \cap 2} \,\, \phi_{2 \cap 3}\right]^{\top}\hspace{-0.5em};\, \mu_{\text{log}}, \, \Sigma_{\text{log}})$.
The choice of $\lambda_{2}$ is critical; by controlling the contribution of $\pd_{2}$ to $\pd_{\text{pool}}$, $\lambda_{2}$ controls the degree of correlation present in the latter.
The right hand column of Figure \ref{fig:pooled_densities_plot} illustrates this phenomena.
When $\lambda_{1} = \lambda_{3} = 0 \implies \lambda_{2} = 1$, all correlation in $\pd_{2}$ is present in $\pd_{\text{pool}}$.
The correlation decreases for increasing values of $\lambda_{1}$ until $\lambda_{1} = \lambda_{3} = 0.5 \implies \lambda_{2} = 0$, where no correlation persists.

# Diagnostics for the owls example

## Stage one diagnostics

#### Numerical diagnostics

\input{tex-input/owls-example/appendix-info/0010-stage-one-diagnostics.tex}

#### Visual diagnostics

```{r stage_one_mcmc_trace_capture_recapture, fig.cap = "Stage one trace plot of the melded quantities in the capture recapture submodel."}
knitr::include_graphics("plots/owls-example/stage-one-diagnostics-capture-recapture.png")
```

```{r stage_one_mcmc_trace_fecundity, fig.cap = "Stage one trace plot of the parameter in the fecundity submodel."}
knitr::include_graphics("plots/owls-example/stage-one-diagnostics-fecundity.png")
```

## Stage two diagnostics

#### Numerical diagnostics

\input{tex-input/owls-example/appendix-info/0020-stage-two-diagnostics.tex}

We include $\alpha_{5}$ because it has the maximum $\widehat{R}$ and minimum Bulk ESS.

#### Visual diagnostics

```{r stage_two_mcmc_diags, fig.cap = "Stage two trace and rank plots of the melded quantities."}
knitr::include_graphics("plots/owls-example/stage-two-diagnostics.png")
```

# Diagnostics for the surv example



# General $\Nm$ case of the melded model, pooled priors.

# Markov melding is sensitive to the order in which the submodels are considered

- Maths / argument goes here, in text sentence goes something like "A possible two-step approach for combining these models is to apply Markov melding to submodels 1 and 2 in step one, then apply it again to the result of step one and submodel 3. However, as we show in Appendix \ref{the-right-appendix-name}, this result of this process is dependent on whether one considers submodels 1 and 2 in step one, or submodels 2 and 3. This dependence is undesirable, and to address it we now develop a modified version of markov melding that is order insensitive."
